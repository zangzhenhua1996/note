



<!doctype html>
<html lang="zh" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      <meta http-equiv="x-ua-compatible" content="ie=edge">
      
        <meta name="description" content="学习笔记">
      
      
        <link rel="canonical" href="https://zangzhenhua1996.github.io/note/python-web/024 scrapy爬虫框架/">
      
      
        <meta name="author" content="臧珍华">
      
      
        <meta name="lang:clipboard.copy" content="复制">
      
        <meta name="lang:clipboard.copied" content="已复制">
      
        <meta name="lang:search.language" content="ja">
      
        <meta name="lang:search.pipeline.stopwords" content="True">
      
        <meta name="lang:search.pipeline.trimmer" content="True">
      
        <meta name="lang:search.result.none" content="没有找到符合条件的结果">
      
        <meta name="lang:search.result.one" content="找到 1 个符合条件的结果">
      
        <meta name="lang:search.result.other" content="# 个符合条件的结果">
      
        <meta name="lang:search.tokenizer" content="[\uff0c\u3002]+">
      
      <link rel="shortcut icon" href="../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.0.4, mkdocs-material-4.4.3">
    
    
      
        <title>024 scrapy爬虫框架 - 臧珍华的博客</title>
      
    
    
      <link rel="stylesheet" href="../../assets/stylesheets/application.30686662.css">
      
        <link rel="stylesheet" href="../../assets/stylesheets/application-palette.a8b3c06d.css">
      
      
        
        
        <meta name="theme-color" content="#757575">
      
    
    
      <script src="../../assets/javascripts/modernizr.74668098.js"></script>
    
    
      
        <link href="https://fonts.gstatic.com" rel="preconnect" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,400,400i,700|Roboto+Mono&display=fallback">
        <style>body,input{font-family:"Roboto","Helvetica Neue",Helvetica,Arial,sans-serif}code,kbd,pre{font-family:"Roboto Mono","Courier New",Courier,monospace}</style>
      
    
    <link rel="stylesheet" href="../../assets/fonts/material-icons.css">
    
    
    
      
    
    
  </head>
  
    
    
    <body dir="ltr" data-md-color-primary="grey" data-md-color-accent="pink">
  
    <svg class="md-svg">
      <defs>
        
        
      </defs>
    </svg>
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" data-md-component="overlay" for="__drawer"></label>
    
      <a href="#scrapy" tabindex="1" class="md-skip">
        跳转至
      </a>
    
    
      <header class="md-header" data-md-component="header">
  <nav class="md-header-nav md-grid">
    <div class="md-flex">
      <div class="md-flex__cell md-flex__cell--shrink">
        <a href="https://zangzhenhua1996.github.io/note/" title="臧珍华的博客" class="md-header-nav__button md-logo">
          
            <i class="md-icon"></i>
          
        </a>
      </div>
      <div class="md-flex__cell md-flex__cell--shrink">
        <label class="md-icon md-icon--menu md-header-nav__button" for="__drawer"></label>
      </div>
      <div class="md-flex__cell md-flex__cell--stretch">
        <div class="md-flex__ellipsis md-header-nav__title" data-md-component="title">
          
            <span class="md-header-nav__topic">
              臧珍华的博客
            </span>
            <span class="md-header-nav__topic">
              
                024 scrapy爬虫框架
              
            </span>
          
        </div>
      </div>
      <div class="md-flex__cell md-flex__cell--shrink">
        
          <label class="md-icon md-icon--search md-header-nav__button" for="__search"></label>
          
<div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" placeholder="搜索" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="query" data-md-state="active">
      <label class="md-icon md-search__icon" for="__search"></label>
      <button type="reset" class="md-icon md-search__icon" data-md-component="reset" tabindex="-1">
        &#xE5CD;
      </button>
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="result">
          <div class="md-search-result__meta">
            键入以开始搜索
          </div>
          <ol class="md-search-result__list"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
        
      </div>
      
        <div class="md-flex__cell md-flex__cell--shrink">
          <div class="md-header-nav__source">
            


  

<a href="https://www.jianshu.com/u/21b46dcb7c44" title="前往 Github 仓库" class="md-source" data-md-source="">
  
  <div class="md-source__repository">
    I love AnFei
  </div>
</a>
          </div>
        </div>
      
    </div>
  </nav>
</header>
    
    <div class="md-container">
      
        
      
      
        

  

<nav class="md-tabs md-tabs--active" data-md-component="tabs">
  <div class="md-tabs__inner md-grid">
    <ul class="md-tabs__list">
      
        
  <li class="md-tabs__item">
    
      <a href="../.." class="md-tabs__link">
        介绍
      </a>
    
  </li>

      
        
  
  
    <li class="md-tabs__item">
      
        <a href="../../情感语录/001 吾日三省吾身/" class="md-tabs__link">
          情感语录
        </a>
      
    </li>
  

      
        
  
  
    <li class="md-tabs__item">
      
        <a href="../../python学习/074 IntellIJ Idea内存不足时怎么设置/" class="md-tabs__link">
          python
        </a>
      
    </li>
  

      
        
  
  
    <li class="md-tabs__item">
      
        <a href="../038 Selenium的WebDriver API元素定位中的XPath和CSS/" class="md-tabs__link md-tabs__link--active">
          python web
        </a>
      
    </li>
  

      
        
  
  
    <li class="md-tabs__item">
      
        <a href="../../数据结构与算法Python/09-图_problem-solving-with-algorithms-and-data-structure-usingpython-中文/" class="md-tabs__link">
          python 数据结构与算法
        </a>
      
    </li>
  

      
        
  
  
    <li class="md-tabs__item">
      
        <a href="../../机器学习/013 进入tensorboard/" class="md-tabs__link">
          机器学习
        </a>
      
    </li>
  

      
        
  
  
    <li class="md-tabs__item">
      
        <a href="../../深度学习/010 一文详解深度学习中的Normalization：BNLNWN/" class="md-tabs__link">
          深度学习
        </a>
      
    </li>
  

      
        
  
  
    <li class="md-tabs__item">
      
        <a href="../../力扣刷题/066-质因数/" class="md-tabs__link">
          每天一道力扣题
        </a>
      
    </li>
  

      
        
  
  
    <li class="md-tabs__item">
      
        <a href="../../java学习/029-IntelliJ-IDEA-2019-快捷键终极大全/" class="md-tabs__link">
          java学习
        </a>
      
    </li>
  

      
        
  
  
    <li class="md-tabs__item">
      
        <a href="../../数据库/013 Redis使用密码登录/" class="md-tabs__link">
          数据库
        </a>
      
    </li>
  

      
        
  
  
    <li class="md-tabs__item">
      
        <a href="../../windows10系统使用/028 win10电脑无线wifi总是掉线断网怎么解决/" class="md-tabs__link">
          windows10系统使用
        </a>
      
    </li>
  

      
        
  
  
    <li class="md-tabs__item">
      
        <a href="../../ubuntu系统的使用/054 ubuntu18.04VNC远程配置/" class="md-tabs__link">
          ubuntu系统的使用
        </a>
      
    </li>
  

      
        
  
  
    <li class="md-tabs__item">
      
        <a href="../../未分类/010 ssh远程链接服务器，避免因断网而中断训练方法/" class="md-tabs__link">
          未分类
        </a>
      
    </li>
  

      
    </ul>
  </div>
</nav>
      
      <main class="md-main" role="main">
        <div class="md-main__inner md-grid" data-md-component="container">
          
            
              <div class="md-sidebar md-sidebar--primary" data-md-component="navigation">
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    <nav class="md-nav md-nav--primary" data-md-level="0">
  <label class="md-nav__title md-nav__title--site" for="__drawer">
    <a href="https://zangzhenhua1996.github.io/note/" title="臧珍华的博客" class="md-nav__button md-logo">
      
        <i class="md-icon"></i>
      
    </a>
    臧珍华的博客
  </label>
  
    <div class="md-nav__source">
      


  

<a href="https://www.jianshu.com/u/21b46dcb7c44" title="前往 Github 仓库" class="md-source" data-md-source="">
  
  <div class="md-source__repository">
    I love AnFei
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
      


  <li class="md-nav__item">
    <a href="../.." title="介绍" class="md-nav__link">
      介绍
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-2" type="checkbox" id="nav-2">
    
    <label class="md-nav__link" for="nav-2">
      情感语录
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="1">
      <label class="md-nav__title" for="nav-2">
        情感语录
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../../情感语录/001 吾日三省吾身/" title="001 吾日三省吾身" class="md-nav__link">
      001 吾日三省吾身
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../情感语录/002 学校生活/" title="002 学校生活" class="md-nav__link">
      002 学校生活
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

    
      
      
      


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-3" type="checkbox" id="nav-3">
    
    <label class="md-nav__link" for="nav-3">
      python
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="1">
      <label class="md-nav__title" for="nav-3">
        python
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../../python学习/074 IntellIJ Idea内存不足时怎么设置/" title="074 IntellIJ Idea内存不足时怎么设置" class="md-nav__link">
      074 IntellIJ Idea内存不足时怎么设置
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../python学习/073 f-String - Python3 字符串格式化利器 - Python Weekly EP1/" title="073 f-String - Python3 字符串格式化利器 - Python Weekly EP1" class="md-nav__link">
      073 f-String - Python3 字符串格式化利器 - Python Weekly EP1
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../python学习/072 14张思维导图构建python核心知识体系/" title="072 14张思维导图构建python核心知识体系" class="md-nav__link">
      072 14张思维导图构建python核心知识体系
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../python学习/071 IDEA几个常用的设置设置空格显示成小点、显示行数、 Ctrl + 鼠标滚轮 快捷键来控制代码字体大小显示、护眼背景色/" title="071 IDEA几个常用的设置:设置空格显示成小点、显示行数、 Ctrl + 鼠标滚轮 快捷键来控制代码字体大小显示、护眼背景色" class="md-nav__link">
      071 IDEA几个常用的设置:设置空格显示成小点、显示行数、 Ctrl + 鼠标滚轮 快捷键来控制代码字体大小显示、护眼背景色
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../python学习/070 部署mkdocs 到码云(gitee)/" title="070 部署mkdocs 到码云(gitee)" class="md-nav__link">
      070 部署mkdocs 到码云(gitee)
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../python学习/069 如何快速的使用cmd激活环境并启动python脚本/" title="069 如何快速的使用cmd激活环境并启动python脚本" class="md-nav__link">
      069 如何快速的使用cmd激活环境并启动python脚本
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../python学习/067 Pycharm 运行程序后如何 如何查看变量的值/" title="067 Pycharm 运行程序后如何 如何查看变量的值" class="md-nav__link">
      067 Pycharm 运行程序后如何 如何查看变量的值
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../python学习/066-spyder升级4.0全新版本/" title="066 spyder升级4.0全新版本" class="md-nav__link">
      066 spyder升级4.0全新版本
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../python学习/065-Jupyter Notebook 远程访问配置/" title="065 Jupyter_Notebook 远程访问配置" class="md-nav__link">
      065 Jupyter_Notebook 远程访问配置
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../python学习/064 python科学计算库Sympy指南/" title="064 python科学计算库Sympy指南" class="md-nav__link">
      064 python科学计算库Sympy指南
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../python学习/063-vscode-高亮提示/" title="063 vscode-高亮提示" class="md-nav__link">
      063 vscode-高亮提示
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../python学习/062-Python-os-path()-模块/" title="062 Python-os-path()-模块" class="md-nav__link">
      062 Python-os-path()-模块
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../python学习/061-基于mkdocs-material搭建个人静态博客/" title="061 基于mkdocs-material搭建个人静态博客" class="md-nav__link">
      061 基于mkdocs-material搭建个人静态博客
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../python学习/060-vscode-ubuntu18-04-空格小/" title="060 vscode-ubuntu18-04-空格小" class="md-nav__link">
      060 vscode-ubuntu18-04-空格小
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../python学习/060-cuda及cudann的配置安装/" title="060 cuda及cudann的配置安装" class="md-nav__link">
      060 cuda及cudann的配置安装
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../python学习/059-在vscode中显示空格和tab符号/" title="059 在vscode中显示空格和tab符号" class="md-nav__link">
      059 在vscode中显示空格和tab符号
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../python学习/058-VS-code快捷键/" title="058 VS-code快捷键" class="md-nav__link">
      058 VS-code快捷键
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../python学习/057 B站缓存视频重命名/" title="057 B站缓存视频重命名" class="md-nav__link">
      057 B站缓存视频重命名
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../python学习/056 python中的全局变量/" title="056 python中的全局变量" class="md-nav__link">
      056 python中的全局变量
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../python学习/055  Python 中 （&，）和（and，or）之间的区别/" title="055 Python 中 （&，）和（and，or）之间的区别" class="md-nav__link">
      055 Python 中 （&，）和（and，or）之间的区别
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../python学习/054 python多任务多进程/" title="054 python多任务多进程" class="md-nav__link">
      054 python多任务多进程
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../python学习/053 python多任务多线程/" title="053 python多任务多线程" class="md-nav__link">
      053 python多任务多线程
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../python学习/052-140种Python标准库、第三方库和外部工具都有了/" title="052 140种Python标准库、第三方库和外部工具都有了" class="md-nav__link">
      052 140种Python标准库、第三方库和外部工具都有了
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../python学习/051-图解NumPy，这是理解数组最形象的一份教程了/" title="051 图解NumPy，这是理解数组最形象的一份教程了" class="md-nav__link">
      051 图解NumPy，这是理解数组最形象的一份教程了
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../python学习/050-Python的zip函数/" title="050 Python的zip函数" class="md-nav__link">
      050 Python的zip函数
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../python学习/049-map函数/" title="049 map函数" class="md-nav__link">
      049 map函数
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../python学习/048-sys模块/" title="048 sys模块" class="md-nav__link">
      048 sys模块
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../python学习/047-opencv-python-怎么读取视频以及获得视频的相应参数/" title="047 opencv-python-怎么读取视频以及获得视频的相应参数" class="md-nav__link">
      047 opencv-python-怎么读取视频以及获得视频的相应参数
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../python学习/046-将文件夹中视频按照横屏竖屏进行分类/" title="046 将文件夹中视频按照横屏竖屏进行分类" class="md-nav__link">
      046 将文件夹中视频按照横屏竖屏进行分类
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../python学习/045-python-的join方法/" title="045 python-的join方法" class="md-nav__link">
      045 python-的join方法
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../python学习/044-python的切片/" title="044 python的切片" class="md-nav__link">
      044 python的切片
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../python学习/043-用python写了一个壁纸切换的系统/" title="043 用python写了一个壁纸切换的系统" class="md-nav__link">
      043 用python写了一个壁纸切换的系统
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../python学习/042-将文件夹中图片按照横屏竖屏进行分类/" title="042 将文件夹中图片按照横屏竖屏进行分类" class="md-nav__link">
      042 将文件夹中图片按照横屏竖屏进行分类
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../python学习/041 python正则表达式/" title="041 python正则表达式" class="md-nav__link">
      041 python正则表达式
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../python学习/040 python多任务协程/" title="040 python多任务协程" class="md-nav__link">
      040 python多任务协程
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../python学习/039 matplotlib绘图的使用/" title="039 matplotlib绘图的使用" class="md-nav__link">
      039 matplotlib绘图的使用
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../python学习/038 numpy常用/" title="038 numpy常用" class="md-nav__link">
      038 numpy常用
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../python学习/037 pyqt5学习/" title="037 pyqt5学习" class="md-nav__link">
      037 pyqt5学习
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../python学习/036-pandas常用/" title="036 pandas常用" class="md-nav__link">
      036 pandas常用
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../python学习/035python中图像处理的工具Pillow的使用/" title="035 python中图像处理的工具Pillow的使用" class="md-nav__link">
      035 python中图像处理的工具Pillow的使用
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../python学习/034Python代码写得丑怎么办？/" title="034 Python代码写得丑怎么办？" class="md-nav__link">
      034 Python代码写得丑怎么办？
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../python学习/033在使用jupyter-notebook明明安装了包,却导入失败-/" title="033 在使用jupyter-notebook明明安装了包,却导入失败-" class="md-nav__link">
      033 在使用jupyter-notebook明明安装了包,却导入失败-
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../python学习/032pandas常用的函数/" title="032 pandas常用的函数" class="md-nav__link">
      032 pandas常用的函数
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../python学习/031python自测100题/" title="031 python自测100题" class="md-nav__link">
      031 python自测100题
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../python学习/030Python面试｜一文让你读懂if-__name__=='__main__'的含义/" title="030 Python面试｜一文让你读懂if-__name__=='__main__'的含义" class="md-nav__link">
      030 Python面试｜一文让你读懂if-__name__=='__main__'的含义
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../python学习/029python自动拷贝优盘的指定后缀文件/" title="029 python自动拷贝优盘的指定后缀文件" class="md-nav__link">
      029 python自动拷贝优盘的指定后缀文件
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../python学习/028获取指定路径所有文件的路径名并进行筛选/" title="028 获取指定路径所有文件的路径名并进行筛选" class="md-nav__link">
      028 获取指定路径所有文件的路径名并进行筛选
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../python学习/027获取指定路径所有文件的路径名/" title="027 获取指定路径所有文件的路径名" class="md-nav__link">
      027 获取指定路径所有文件的路径名
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../python学习/026python自动拷贝优盘的所有内容/" title="026 python自动拷贝优盘的所有内容" class="md-nav__link">
      026 python自动拷贝优盘的所有内容
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../python学习/025python模块之psutil详解/" title="025 python模块之psutil详解" class="md-nav__link">
      025 python模块之psutil详解
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../python学习/024python的各种推导式/" title="024 python的各种推导式" class="md-nav__link">
      024 python的各种推导式
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../python学习/023python多进程/" title="023 python多进程" class="md-nav__link">
      023 python多进程
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../python学习/022-python多线程(修改借鉴莫烦python)/" title="022 python多线程(修改借鉴莫烦python)" class="md-nav__link">
      022 python多线程(修改借鉴莫烦python)
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../python学习/021-pickle-保存数据/" title="021-pickle-保存数据" class="md-nav__link">
      021-pickle-保存数据
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../python学习/020-python错题集/" title="020 python错题集" class="md-nav__link">
      020 python错题集
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../python学习/019python-进度条-tqdm的使用/" title="019 python-进度条-tqdm的使用" class="md-nav__link">
      019 python-进度条-tqdm的使用
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../python学习/018-python数据科学速查表___为个人方便查看转载/" title="018 python数据科学速查表___为个人方便查看转载" class="md-nav__link">
      018 python数据科学速查表___为个人方便查看转载
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../python学习/017python随记/" title="017 python随记" class="md-nav__link">
      017 python随记
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../python学习/016python-numpy的简单实用杂乱/" title="016 python-numpy的简单实用杂乱" class="md-nav__link">
      016 python-numpy的简单实用杂乱
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../python学习/015python模块和包/" title="015 python模块和包" class="md-nav__link">
      015 python模块和包
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../python学习/014python异常/" title="014 python异常" class="md-nav__link">
      014 python异常
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../python学习/013python单例设计模式/" title="013 python单例设计模式" class="md-nav__link">
      013 python单例设计模式
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../python学习/012python类属性和类方法/" title="012 python类属性和类方法" class="md-nav__link">
      012 python类属性和类方法
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../python学习/011python多态/" title="011 python多态" class="md-nav__link">
      011 python多态
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../python学习/010python继承/" title="010 python继承" class="md-nav__link">
      010 python继承
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../python学习/009python私有属性和私有方法/" title="009 python私有属性和私有方法" class="md-nav__link">
      009 python私有属性和私有方法
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../python学习/008python面向对象编程/" title="008 python面向对象编程" class="md-nav__link">
      008 python面向对象编程
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../python学习/007python中赋值,浅拷贝,深拷贝的一些解释/" title="007python中赋值,浅拷贝,深拷贝的一些解释" class="md-nav__link">
      007python中赋值,浅拷贝,深拷贝的一些解释
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../python学习/006pythoneval函数/" title="006 pythoneval函数" class="md-nav__link">
      006 pythoneval函数
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../python学习/005python_中文转换成拼音_xpinyin包/" title="005 python中文转换成拼音xpinyin包" class="md-nav__link">
      005 python中文转换成拼音xpinyin包
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../python学习/004python中glob模块的使用/" title="004 python中glob模块的使用" class="md-nav__link">
      004 python中glob模块的使用
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../python学习/003python使用shutil-模块移动复制文件/" title="003 python使用shutil模块移动复制文件" class="md-nav__link">
      003 python使用shutil模块移动复制文件
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../python学习/002 python操作文件/" title="002 python操作文件" class="md-nav__link">
      002 python操作文件
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../python学习/001 jupyter notebook快捷键/" title="001 jupyter notebook快捷键" class="md-nav__link">
      001 jupyter notebook快捷键
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

    
      
      
      

  


  <li class="md-nav__item md-nav__item--active md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-4" type="checkbox" id="nav-4" checked>
    
    <label class="md-nav__link" for="nav-4">
      python web
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="1">
      <label class="md-nav__title" for="nav-4">
        python web
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../038 Selenium的WebDriver API元素定位中的XPath和CSS/" title="038 Selenium的WebDriver API元素定位中的XPath和CSS" class="md-nav__link">
      038 Selenium的WebDriver API元素定位中的XPath和CSS
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../037 Python中pytesseract库的使用以及注意事项(图片ocr)/" title="037 Python中pytesseract库的使用以及注意事项(图片ocr)" class="md-nav__link">
      037 Python中pytesseract库的使用以及注意事项(图片ocr)
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../036 Python实现从url中提取域名的几种方法/" title="036 Python实现从url中提取域名的几种方法" class="md-nav__link">
      036 Python实现从url中提取域名的几种方法
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../035 requests请求返回内容 中文乱码问题/" title="035 requests请求返回内容 中文乱码问题" class="md-nav__link">
      035 requests请求返回内容 中文乱码问题
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../034 scrapy设置随机请求头和代理/" title="034 scrapy设置随机请求头和代理" class="md-nav__link">
      034 scrapy设置随机请求头和代理
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../033 scrapy爬虫框架和selenium的配合使用/" title="033 scrapy爬虫框架和selenium的配合使用" class="md-nav__link">
      033 scrapy爬虫框架和selenium的配合使用
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../032 selenium启动Chrome配置参数问题/" title="032 selenium启动Chrome配置参数问题" class="md-nav__link">
      032 selenium启动Chrome配置参数问题
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../031 Selenium之动作链（ActionChains）/" title="031 Selenium之动作链（ActionChains）" class="md-nav__link">
      031 Selenium之动作链（ActionChains）
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../030 flask的使用/" title="030 flask的使用" class="md-nav__link">
      030 flask的使用
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../029 Splash的使用/" title="029 Splash的使用" class="md-nav__link">
      029 Splash的使用
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../028 cookies池搭建/" title="028 cookies池搭建" class="md-nav__link">
      028 cookies池搭建
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../027 爬取半次元图片/" title="027 爬取半次元图片" class="md-nav__link">
      027 爬取半次元图片
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../026 极验/" title="026 极验" class="md-nav__link">
      026 极验
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../025 PostMan使用教程/" title="025 PostMan使用教程" class="md-nav__link">
      025 PostMan使用教程
    </a>
  </li>

        
          
          
          

  


  <li class="md-nav__item md-nav__item--active">
    
    <input class="md-toggle md-nav__toggle" data-md-toggle="toc" type="checkbox" id="__toc">
    
      
    
    
      <label class="md-nav__link md-nav__link--active" for="__toc">
        024 scrapy爬虫框架
      </label>
    
    <a href="./" title="024 scrapy爬虫框架" class="md-nav__link md-nav__link--active">
      024 scrapy爬虫框架
    </a>
    
      
<nav class="md-nav md-nav--secondary">
  
  
    
  
  
    <label class="md-nav__title" for="__toc">目录</label>
    <ul class="md-nav__list" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#_1" class="md-nav__link">
    分类 编程技术
  </a>
  
</li>
      
      
      
      
      
    </ul>
  
</nav>
    
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../023 正则表达式/" title="023 正则表达式" class="md-nav__link">
      023 正则表达式
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../022 selenium/" title="022 selenium" class="md-nav__link">
      022 selenium
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../021 pyquery/" title="021 pyquery" class="md-nav__link">
      021 pyquery
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../020 requests/" title="020 requests" class="md-nav__link">
      020 requests
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../019 bs4库/" title="019 bs4库" class="md-nav__link">
      019 bs4库
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../018 urllib/" title="018 urllib" class="md-nav__link">
      018 urllib
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../017 爬虫基本原理/" title="017 爬虫基本原理" class="md-nav__link">
      017 爬虫基本原理
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../016 xpath的使用/" title="016 xpath的使用" class="md-nav__link">
      016 xpath的使用
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../015-python项目离线部署/" title="015 python项目离线部署" class="md-nav__link">
      015 python项目离线部署
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../014-天天生鲜项目指令/" title="014 天天生鲜项目指令" class="md-nav__link">
      014 天天生鲜项目指令
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../014-windows下使用-fdfs_client-上传文件/" title="014 windows下使用_fdfs_client-上传文件" class="md-nav__link">
      014 windows下使用_fdfs_client-上传文件
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../013-天天生鲜项目简略中/" title="013 天天生鲜项目简略中" class="md-nav__link">
      013 天天生鲜项目简略中
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../013-天天生鲜项目简略上/" title="013 天天生鲜项目简略上" class="md-nav__link">
      013 天天生鲜项目简略上
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../012-分布式图片服务器FastDFS/" title="012 分布式图片服务器FastDFS" class="md-nav__link">
      012 分布式图片服务器FastDFS
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../011-Django框架使用步骤/" title="011 Django框架使用步骤" class="md-nav__link">
      011 Django框架使用步骤
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../010 网络知识补充/" title="010 网络知识补充" class="md-nav__link">
      010 网络知识补充
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../009-13--python提高-2/" title="009 13--python提高-2" class="md-nav__link">
      009 13--python提高-2
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../008-12--python提高-1/" title="008 12--python提高-1" class="md-nav__link">
      008 12--python提高-1
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../007 19. 闭包、装饰器/" title="007 19. 闭包、装饰器" class="md-nav__link">
      007 19. 闭包、装饰器
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../006 18. WSGI、mini-web框架/" title="006 18. WSGI、mini-web框架" class="md-nav__link">
      006 18. WSGI、mini-web框架
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../005--11-网络通信过程/" title="005 11-网络通信过程" class="md-nav__link">
      005  11-网络通信过程
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../004--10--web服务器-并发服务器2/" title="004 10-web服务器-并发服务器2" class="md-nav__link">
      004  10-web服务器-并发服务器2
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../003-9--http协议、web服务器-并发服务器1/" title="003 9--http协议、web服务器-并发服务器1" class="md-nav__link">
      003 9--http协议、web服务器-并发服务器1
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../002-网络tcp/" title="002 网络tcp" class="md-nav__link">
      002 网络tcp
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../001-网络udp/" title="001 网络udp" class="md-nav__link">
      001 网络udp
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

    
      
      
      


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-5" type="checkbox" id="nav-5">
    
    <label class="md-nav__link" for="nav-5">
      python 数据结构与算法
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="1">
      <label class="md-nav__title" for="nav-5">
        python 数据结构与算法
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../../数据结构与算法Python/09-图_problem-solving-with-algorithms-and-data-structure-usingpython-中文/" title="09-图_problem-solving-with-algorithms-and-data-structure-usingpython-中文" class="md-nav__link">
      09-图_problem-solving-with-algorithms-and-data-structure-usingpython-中文
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../数据结构与算法Python/08-图-基本概念及python实现/" title="08-图-基本概念及python实现" class="md-nav__link">
      08-图-基本概念及python实现
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../数据结构与算法Python/07-树与树算法/" title="07-树与树算法" class="md-nav__link">
      07-树与树算法
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../数据结构与算法Python/06-排序与搜索-数据结构与算法（Python）/" title="06-排序与搜索-数据结构与算法（Python）" class="md-nav__link">
      06-排序与搜索-数据结构与算法（Python）
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../数据结构与算法Python/05-队列-数据结构与算法（Python）/" title="05-队列-数据结构与算法（Python）" class="md-nav__link">
      05-队列-数据结构与算法（Python）
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../数据结构与算法Python/04-栈-数据结构与算法（Python）/" title="04-栈-数据结构与算法（Python）" class="md-nav__link">
      04-栈-数据结构与算法（Python）
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../数据结构与算法Python/03-链表-数据结构与算法（Python）/" title="03-链表-数据结构与算法（Python）" class="md-nav__link">
      03-链表-数据结构与算法（Python）
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../数据结构与算法Python/02-顺序表-数据结构与算法（Python）/" title="02-顺序表-数据结构与算法（Python）" class="md-nav__link">
      02-顺序表-数据结构与算法（Python）
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../数据结构与算法Python/01-引入概念-数据结构与算法（Python）/" title="01-引入概念-数据结构与算法（Python）" class="md-nav__link">
      01-引入概念-数据结构与算法（Python）
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../数据结构与算法Python/00-数据结构与算法（Python）/" title="00-数据结构与算法（Python）" class="md-nav__link">
      00-数据结构与算法（Python）
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

    
      
      
      


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-6" type="checkbox" id="nav-6">
    
    <label class="md-nav__link" for="nav-6">
      机器学习
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="1">
      <label class="md-nav__title" for="nav-6">
        机器学习
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../../机器学习/013 进入tensorboard/" title="013 进入tensorboard" class="md-nav__link">
      013 进入tensorboard
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../机器学习/012-Keras使用tensorboard训练过程可视化踩过的坑/" title="012-Keras使用tensorboard训练过程可视化踩过的坑" class="md-nav__link">
      012-Keras使用tensorboard训练过程可视化踩过的坑
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../机器学习/011-关于交叉验证与偏差-方差的一连串理解/" title="011-关于交叉验证与偏差-方差的一连串理解" class="md-nav__link">
      011-关于交叉验证与偏差-方差的一连串理解
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../机器学习/010-统计学习方法--统计学习方法概论要点加代码/" title="010-统计学习方法--统计学习方法概论要点加代码" class="md-nav__link">
      010-统计学习方法--统计学习方法概论要点加代码
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../机器学习/009-统计学习方法--统计学习方法概论详细/" title="009-统计学习方法--统计学习方法概论详细" class="md-nav__link">
      009-统计学习方法--统计学习方法概论详细
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../机器学习/008-机器学习概念回顾、精确率、召回率、F1-score、准确率、AUC、ROC曲线/" title="008-机器学习概念回顾、精确率、召回率、F1-score、准确率、AUC、ROC曲线" class="md-nav__link">
      008-机器学习概念回顾、精确率、召回率、F1-score、准确率、AUC、ROC曲线
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../机器学习/007-机器学习中的维数灾难/" title="007-机器学习中的维数灾难" class="md-nav__link">
      007-机器学习中的维数灾难
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../机器学习/006-sklearn模型的保存加载/" title="006-sklearn模型的保存加载" class="md-nav__link">
      006-sklearn模型的保存加载
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../机器学习/005-sklearn之交叉验证/" title="005-sklearn之交叉验证" class="md-nav__link">
      005-sklearn之交叉验证
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../机器学习/004-sklearn：特征提取，常用模型，交叉验证/" title="004-sklearn：特征提取，常用模型，交叉验证" class="md-nav__link">
      004-sklearn：特征提取，常用模型，交叉验证
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../机器学习/003-sklearn学习,选择模型流程,应用模型(鸢尾花的例子),使用模型的步骤：,Sklearn中的数据集-,预处理数据/" title="003-sklearn学习,选择模型流程,应用模型(鸢尾花的例子),使用模型的步骤：,Sklearn中的数据集-,预处理数据" class="md-nav__link">
      003-sklearn学习,选择模型流程,应用模型(鸢尾花的例子),使用模型的步骤：,Sklearn中的数据集-,预处理数据
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../机器学习/002-预处理数据的方法总结（使用sklearn-preprocessing）/" title="002-预处理数据的方法总结（使用sklearn-preprocessing）" class="md-nav__link">
      002-预处理数据的方法总结（使用sklearn-preprocessing）
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../机器学习/001-sklearn-安装，获取数据，数据预处理/" title="001-sklearn-安装，获取数据，数据预处理" class="md-nav__link">
      001-sklearn-安装，获取数据，数据预处理
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

    
      
      
      


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-7" type="checkbox" id="nav-7">
    
    <label class="md-nav__link" for="nav-7">
      深度学习
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="1">
      <label class="md-nav__title" for="nav-7">
        深度学习
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../../深度学习/010 一文详解深度学习中的Normalization：BNLNWN/" title="010 一文详解深度学习中的Normalization：BNLNWN" class="md-nav__link">
      010 一文详解深度学习中的Normalization：BNLNWN
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../深度学习/009 Transformer详解（三）：Transformer 结构/" title="009 Transformer详解（三）：Transformer 结构" class="md-nav__link">
      009 Transformer详解（三）：Transformer 结构
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../深度学习/008 Transformer详解（二）：Attention机制/" title="008 Transformer详解（二）：Attention机制" class="md-nav__link">
      008 Transformer详解（二）：Attention机制
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../深度学习/007 Transformer详解（一）：从RNN到Attention机制/" title="007 Transformer详解（一）：从RNN到Attention机制" class="md-nav__link">
      007 Transformer详解（一）：从RNN到Attention机制
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../深度学习/003 正则化的概念及原因/" title="003 正则化的概念及原因" class="md-nav__link">
      003 正则化的概念及原因
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../深度学习/002 如何选择优化器 optimizer/" title="002 如何选择优化器 optimizer" class="md-nav__link">
      002 如何选择优化器 optimizer
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../深度学习/001 Dropout(1)/" title="001 Dropout(1)" class="md-nav__link">
      001 Dropout(1)
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

    
      
      
      


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-8" type="checkbox" id="nav-8">
    
    <label class="md-nav__link" for="nav-8">
      每天一道力扣题
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="1">
      <label class="md-nav__title" for="nav-8">
        每天一道力扣题
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../../力扣刷题/066-质因数/" title="066-质因数" class="md-nav__link">
      066-质因数
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../力扣刷题/065-完全数的求解/" title="065-完全数的求解" class="md-nav__link">
      065-完全数的求解
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../力扣刷题/064-刷题过程中慎用-[]-is-None/" title="064-刷题过程中慎用-[]-is-None" class="md-nav__link">
      064-刷题过程中慎用-[]-is-None
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../力扣刷题/063-LRU缓存算法的python实现/" title="063-LRU缓存算法的python实现" class="md-nav__link">
      063-LRU缓存算法的python实现
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../力扣刷题/062-力扣刷题-344--反转字符串/" title="062-力扣刷题-344--反转字符串" class="md-nav__link">
      062-力扣刷题-344--反转字符串
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../力扣刷题/061-力扣刷题-23--合并K个排序链表/" title="061-力扣刷题-23--合并K个排序链表" class="md-nav__link">
      061-力扣刷题-23--合并K个排序链表
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../力扣刷题/060-力扣刷题-232--用栈实现队列/" title="060-力扣刷题-232--用栈实现队列" class="md-nav__link">
      060-力扣刷题-232--用栈实现队列
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../力扣刷题/059-力扣刷题-102--二叉树的层次遍历/" title="059-力扣刷题-102--二叉树的层次遍历" class="md-nav__link">
      059-力扣刷题-102--二叉树的层次遍历
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../力扣刷题/058-力扣刷题-226--翻转二叉树/" title="058-力扣刷题-226--翻转二叉树" class="md-nav__link">
      058-力扣刷题-226--翻转二叉树
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../力扣刷题/057-力扣刷题-237删除链表中的节点/" title="057-力扣刷题-237删除链表中的节点" class="md-nav__link">
      057-力扣刷题-237删除链表中的节点
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../力扣刷题/056-力扣刷题-206--反转链表/" title="056-力扣刷题-206--反转链表" class="md-nav__link">
      056-力扣刷题-206--反转链表
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../力扣刷题/055-力扣刷题-1004--最大连续1的个数-III/" title="055-力扣刷题-1004--最大连续1的个数-III" class="md-nav__link">
      055-力扣刷题-1004--最大连续1的个数-III
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../力扣刷题/054-小球反弹的总路程/" title="054-小球反弹的总路程" class="md-nav__link">
      054-小球反弹的总路程
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../力扣刷题/053-力扣刷题-235--二叉搜索树的最近公共祖先/" title="053-力扣刷题-235--二叉搜索树的最近公共祖先" class="md-nav__link">
      053-力扣刷题-235--二叉搜索树的最近公共祖先
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../力扣刷题/052-力扣刷题-162--寻找峰值/" title="052-力扣刷题-162--寻找峰值" class="md-nav__link">
      052-力扣刷题-162--寻找峰值
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../力扣刷题/051-力扣刷题-136--只出现一次的数字/" title="051-力扣刷题-136--只出现一次的数字" class="md-nav__link">
      051-力扣刷题-136--只出现一次的数字
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../力扣刷题/050-二维生物的旅行-754--到达终点数字/" title="050-二维生物的旅行-754--到达终点数字" class="md-nav__link">
      050-二维生物的旅行-754--到达终点数字
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../力扣刷题/049--力扣刷题459--重复的子字符串-pin2字符串构造/" title="049--力扣刷题459--重复的子字符串-pin2字符串构造" class="md-nav__link">
      049--力扣刷题459--重复的子字符串-pin2字符串构造
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../力扣刷题/048-pin题目1/" title="048-pin题目1" class="md-nav__link">
      048-pin题目1
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../力扣刷题/047-力扣刷题-845--数组中的最长山脉/" title="047-力扣刷题-845--数组中的最长山脉" class="md-nav__link">
      047-力扣刷题-845--数组中的最长山脉
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../力扣刷题/046-力扣刷题-125--验证回文串/" title="046-力扣刷题-125--验证回文串" class="md-nav__link">
      046-力扣刷题-125--验证回文串
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../力扣刷题/045-力扣刷题-122--买卖股票的最佳时机-II/" title="045-力扣刷题-122--买卖股票的最佳时机-II" class="md-nav__link">
      045-力扣刷题-122--买卖股票的最佳时机-II
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../力扣刷题/044-力扣刷题-119--杨辉三角-II/" title="044-力扣刷题-119--杨辉三角-II" class="md-nav__link">
      044-力扣刷题-119--杨辉三角-II
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../力扣刷题/043-力扣刷题-121--买卖股票的最佳时机/" title="043-力扣刷题-121--买卖股票的最佳时机" class="md-nav__link">
      043-力扣刷题-121--买卖股票的最佳时机
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../力扣刷题/042-力扣刷题-8--字符串转换整数-(atoi)/" title="042-力扣刷题-8--字符串转换整数-(atoi)" class="md-nav__link">
      042-力扣刷题-8--字符串转换整数-(atoi)
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../力扣刷题/041-力扣刷题-118--杨辉三角/" title="041-力扣刷题-118--杨辉三角" class="md-nav__link">
      041-力扣刷题-118--杨辉三角
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../力扣刷题/040-力扣刷题-535--TinyURL-的加密与解密/" title="040-力扣刷题-535--TinyURL-的加密与解密" class="md-nav__link">
      040-力扣刷题-535--TinyURL-的加密与解密
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../力扣刷题/039-力扣刷题-112--路径总和/" title="039-力扣刷题-112--路径总和" class="md-nav__link">
      039-力扣刷题-112--路径总和
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../力扣刷题/038-力扣刷题-98--验证二叉搜索树/" title="038-力扣刷题-98--验证二叉搜索树" class="md-nav__link">
      038-力扣刷题-98--验证二叉搜索树
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../力扣刷题/037-力扣刷题-110--平衡二叉树--重点进行理解/" title="037-力扣刷题-110--平衡二叉树--重点进行理解" class="md-nav__link">
      037-力扣刷题-110--平衡二叉树--重点进行理解
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../力扣刷题/036-力扣刷题-166--分数到小数/" title="036-力扣刷题-166--分数到小数" class="md-nav__link">
      036-力扣刷题-166--分数到小数
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../力扣刷题/035-字节跳动题目-小球往返路程/" title="035-字节跳动题目-小球往返路程" class="md-nav__link">
      035-字节跳动题目-小球往返路程
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../力扣刷题/034-力扣刷题-88--合并两个有序数组/" title="034-力扣刷题-88--合并两个有序数组" class="md-nav__link">
      034-力扣刷题-88--合并两个有序数组
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../力扣刷题/033-力扣刷题-70--爬楼梯/" title="033-力扣刷题-70--爬楼梯" class="md-nav__link">
      033-力扣刷题-70--爬楼梯
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../力扣刷题/032-力扣刷题-83--删除排序链表中的重复元素/" title="032-力扣刷题-83--删除排序链表中的重复元素" class="md-nav__link">
      032-力扣刷题-83--删除排序链表中的重复元素
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../力扣刷题/031-力扣刷题-101--对称二叉树/" title="031-力扣刷题-101--对称二叉树" class="md-nav__link">
      031-力扣刷题-101--对称二叉树
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../力扣刷题/030-力扣刷题-111--二叉树的最小深度/" title="030-力扣刷题-111--二叉树的最小深度" class="md-nav__link">
      030-力扣刷题-111--二叉树的最小深度
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../力扣刷题/029-力扣刷题-104--二叉树的最大深度/" title="029-力扣刷题-104--二叉树的最大深度" class="md-nav__link">
      029-力扣刷题-104--二叉树的最大深度
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../力扣刷题/028-力扣刷题107--二叉树的层次遍历-II/" title="028-力扣刷题107--二叉树的层次遍历-II" class="md-nav__link">
      028-力扣刷题107--二叉树的层次遍历-II
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../力扣刷题/027-字节跳动笔试题-循环链表实现约瑟夫环/" title="027-字节跳动笔试题-循环链表实现约瑟夫环" class="md-nav__link">
      027-字节跳动笔试题-循环链表实现约瑟夫环
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../力扣刷题/026-力扣刷题-108--将有序数组转换为二叉搜索树/" title="026-力扣刷题-108--将有序数组转换为二叉搜索树" class="md-nav__link">
      026-力扣刷题-108--将有序数组转换为二叉搜索树
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../力扣刷题/025-力扣刷题-100-相同的树/" title="025-力扣刷题-100-相同的树" class="md-nav__link">
      025-力扣刷题-100-相同的树
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../力扣刷题/024-力扣刷题-66--加一/" title="024-力扣刷题-66--加一" class="md-nav__link">
      024-力扣刷题-66--加一
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../力扣刷题/023-力扣刷题-69--x-的平方根/" title="023-力扣刷题-69--x-的平方根" class="md-nav__link">
      023-力扣刷题-69--x-的平方根
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../力扣刷题/022-力扣刷题-二进制求和/" title="022-力扣刷题-二进制求和" class="md-nav__link">
      022-力扣刷题-二进制求和
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../力扣刷题/021-力扣刷题151--翻转字符串里的单词/" title="021-力扣刷题151--翻转字符串里的单词" class="md-nav__link">
      021-力扣刷题151--翻转字符串里的单词
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../力扣刷题/020-力扣刷题-58--最后一个单词的长度/" title="020-力扣刷题-58--最后一个单词的长度" class="md-nav__link">
      020-力扣刷题-58--最后一个单词的长度
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../力扣刷题/019-力扣刷题53--最大子序和/" title="019-力扣刷题53--最大子序和" class="md-nav__link">
      019-力扣刷题53--最大子序和
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../力扣刷题/018-力扣刷题-38--报数/" title="018-力扣刷题-38--报数" class="md-nav__link">
      018-力扣刷题-38--报数
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../力扣刷题/017-46--全排列/" title="017-46--全排列" class="md-nav__link">
      017-46--全排列
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../力扣刷题/016-力扣刷题873--最长的斐波那契子序列的长度/" title="016-力扣刷题873--最长的斐波那契子序列的长度" class="md-nav__link">
      016-力扣刷题873--最长的斐波那契子序列的长度
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../力扣刷题/015-力扣刷题35--搜索插入位置/" title="015-力扣刷题35--搜索插入位置" class="md-nav__link">
      015-力扣刷题35--搜索插入位置
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../力扣刷题/014-力扣刷题9--回文数/" title="014-力扣刷题9--回文数" class="md-nav__link">
      014-力扣刷题9--回文数
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../力扣刷题/013-力扣刷题7--整数反转/" title="013-力扣刷题7--整数反转" class="md-nav__link">
      013-力扣刷题7--整数反转
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../力扣刷题/012-力扣刷题14--最长公共前缀/" title="012-力扣刷题14--最长公共前缀" class="md-nav__link">
      012-力扣刷题14--最长公共前缀
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../力扣刷题/011-力扣刷题21--合并两个有序链表/" title="011-力扣刷题21--合并两个有序链表" class="md-nav__link">
      011-力扣刷题21--合并两个有序链表
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../力扣刷题/010-力扣刷题27--移除元素/" title="010-力扣刷题27--移除元素" class="md-nav__link">
      010-力扣刷题27--移除元素
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../力扣刷题/009-力扣刷题28--实现strStr()/" title="009-力扣刷题28--实现strStr()" class="md-nav__link">
      009-力扣刷题28--实现strStr()
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../力扣刷题/008-力扣刷题20--有效的括号/" title="008-力扣刷题20--有效的括号" class="md-nav__link">
      008-力扣刷题20--有效的括号
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../力扣刷题/007-力扣刷题26--删除排序数组中的重复项/" title="007-力扣刷题26--删除排序数组中的重复项" class="md-nav__link">
      007-力扣刷题26--删除排序数组中的重复项
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../力扣刷题/006-力扣刷题22--括号生成/" title="006-力扣刷题22--括号生成" class="md-nav__link">
      006-力扣刷题22--括号生成
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../力扣刷题/005-力扣刷题13--罗马数字转整数/" title="005-力扣刷题13--罗马数字转整数" class="md-nav__link">
      005-力扣刷题13--罗马数字转整数
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../力扣刷题/004-力扣刷题4--寻找两个有序数组的中位数/" title="004-力扣刷题4--寻找两个有序数组的中位数" class="md-nav__link">
      004-力扣刷题4--寻找两个有序数组的中位数
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../力扣刷题/003-力扣刷题3不含有重复字符的-最长子串-的长度/" title="003-力扣刷题3不含有重复字符的-最长子串-的长度" class="md-nav__link">
      003-力扣刷题3不含有重复字符的-最长子串-的长度
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../力扣刷题/002-力扣刷题2-两数相加/" title="002-力扣刷题2-两数相加" class="md-nav__link">
      002-力扣刷题2-两数相加
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../力扣刷题/001-力扣刷题1--两数之和/" title="001-力扣刷题1--两数之和" class="md-nav__link">
      001-力扣刷题1--两数之和
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

    
      
      
      


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-9" type="checkbox" id="nav-9">
    
    <label class="md-nav__link" for="nav-9">
      java学习
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="1">
      <label class="md-nav__title" for="nav-9">
        java学习
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../../java学习/029-IntelliJ-IDEA-2019-快捷键终极大全/" title="029-IntelliJ-IDEA-2019-快捷键终极大全" class="md-nav__link">
      029-IntelliJ-IDEA-2019-快捷键终极大全
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../java学习/028-day27-反射/" title="028-day27-反射" class="md-nav__link">
      028-day27-反射
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../java学习/027-day26-网络/" title="027-day26-网络" class="md-nav__link">
      027-day26-网络
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../java学习/026-day25-多线程2/" title="026-day25-多线程2" class="md-nav__link">
      026-day25-多线程2
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../java学习/025-day24-多线程1/" title="025-day24-多线程1" class="md-nav__link">
      025-day24-多线程1
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../java学习/024-day22数据流/" title="024-day22数据流" class="md-nav__link">
      024-day22数据流
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../java学习/023-day21--每个讲解到最后的其实才是最需要记住的/" title="023-day21--每个讲解到最后的其实才是最需要记住的" class="md-nav__link">
      023-day21--每个讲解到最后的其实才是最需要记住的
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../java学习/022-day20-递归,IO流/" title="022-day20-递归,IO流" class="md-nav__link">
      022-day20-递归,IO流
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../java学习/021-day19---异常----File----递归----字节流----转换流----字符流----其他流/" title="021-day19---异常----File----递归----字节流----转换流----字符流----其他流" class="md-nav__link">
      021-day19---异常----File----递归----字节流----转换流----字符流----其他流
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../java学习/020-day18-hashmap/" title="020-day18-hashmap" class="md-nav__link">
      020-day18-hashmap
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../java学习/019-day17--hashset/" title="019-day17--hashset" class="md-nav__link">
      019-day17--hashset
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../java学习/018-day16arraylist使用/" title="018-day16arraylist使用" class="md-nav__link">
      018-day16arraylist使用
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../java学习/017-Eclipse-常用快捷键及使用技巧/" title="017-Eclipse-常用快捷键及使用技巧" class="md-nav__link">
      017-Eclipse-常用快捷键及使用技巧
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../java学习/016-day15-集合类/" title="016-day15-集合类" class="md-nav__link">
      016-day15-集合类
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../java学习/015-day14-正则表达式概述及基本使用/" title="015-day14-正则表达式概述及基本使用" class="md-nav__link">
      015-day14-正则表达式概述及基本使用
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../java学习/014-day13-StringBuffer类,数组高级以及Arrays(掌握),(3)Arrays工具类/" title="014-day13-StringBuffer类,数组高级以及Arrays(掌握),(3)Arrays工具类" class="md-nav__link">
      014-day13-StringBuffer类,数组高级以及Arrays(掌握),(3)Arrays工具类
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../java学习/013-day12-API概述,object类,scanner类,string类/" title="013-day12-API概述,object类,scanner类,string类" class="md-nav__link">
      013-day12-API概述,object类,scanner类,string类
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../java学习/012-如何查看jdk的源码/" title="012-如何查看jdk的源码" class="md-nav__link">
      012-如何查看jdk的源码
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../java学习/011-day11java使用eclipse/" title="011-day11java使用eclipse" class="md-nav__link">
      011-day11java使用eclipse
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../java学习/010-day10笔记--包,内部类/" title="010-day10笔记--包,内部类" class="md-nav__link">
      010-day10笔记--包,内部类
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../java学习/009-day09多态/" title="009-day09多态" class="md-nav__link">
      009-day09多态
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../java学习/008-day-08-代码块,继承,final/" title="008-day-08-代码块,继承,final" class="md-nav__link">
      008-day-08-代码块,继承,final
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../java学习/007-day-07-构造方法,创建对象的步骤,练习,static,文档说明书的制作与使用/" title="007-day-07-构造方法,创建对象的步骤,练习,static,文档说明书的制作与使用" class="md-nav__link">
      007-day-07-构造方法,创建对象的步骤,练习,static,文档说明书的制作与使用
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../java学习/006-day06-类的定义及使用,面向对象内存图,匿名对象,封装,this/" title="006-day06-类的定义及使用,面向对象内存图,匿名对象,封装,this" class="md-nav__link">
      006-day06-类的定义及使用,面向对象内存图,匿名对象,封装,this
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../java学习/005-day05,一维数组,二维数组/" title="005-day05,一维数组,二维数组" class="md-nav__link">
      005-day05,一维数组,二维数组
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../java学习/004-day04,for循环,while循环,do_while循环,循环嵌套,控制语句,方法/" title="004-day04,for循环,while循环,do_while循环,循环嵌套,控制语句,方法" class="md-nav__link">
      004-day04,for循环,while循环,do_while循环,循环嵌套,控制语句,方法
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../java学习/003-day03,逻辑运算符,位运算符,三元运算符,顺序结构,选择结构if,switch/" title="003-day03,逻辑运算符,位运算符,三元运算符,顺序结构,选择结构if,switch" class="md-nav__link">
      003-day03,逻辑运算符,位运算符,三元运算符,顺序结构,选择结构if,switch
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../java学习/002-day02,常量,进制转换,数据类型转换,算数运算符,赋值运算符,关系运算符/" title="002-day02,常量,进制转换,数据类型转换,算数运算符,赋值运算符,关系运算符" class="md-nav__link">
      002-day02,常量,进制转换,数据类型转换,算数运算符,赋值运算符,关系运算符
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../java学习/001-day01,java初探以及说明/" title="001-day01,java初探以及说明" class="md-nav__link">
      001-day01,java初探以及说明
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

    
      
      
      


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-10" type="checkbox" id="nav-10">
    
    <label class="md-nav__link" for="nav-10">
      数据库
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="1">
      <label class="md-nav__title" for="nav-10">
        数据库
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../../数据库/013 Redis使用密码登录/" title="013 Redis使用密码登录" class="md-nav__link">
      013 Redis使用密码登录
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../数据库/012 mysql mysqldump 命令导出指定表的数据/" title="012 mysql mysqldump 命令导出指定表的数据" class="md-nav__link">
      012 mysql mysqldump 命令导出指定表的数据
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../数据库/011 Mysql创建用户并授权以及开启远程访问/" title="011 Mysql创建用户并授权以及开启远程访问" class="md-nav__link">
      011 Mysql创建用户并授权以及开启远程访问
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../数据库/010 windows下通过批处理脚本启动redis/" title="010 windows下通过批处理脚本启动redis" class="md-nav__link">
      010 windows下通过批处理脚本启动redis
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../数据库/009 Redis 安装/" title="009 Redis 安装" class="md-nav__link">
      009 Redis 安装
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../数据库/008 便携版mysql安装配置/" title="008 便携版mysql安装配置" class="md-nav__link">
      008 便携版mysql安装配置
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../数据库/007-redis总结/" title="007-redis总结" class="md-nav__link">
      007-redis总结
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../数据库/006-mysql的一些底层原理/" title="006-mysql的一些底层原理" class="md-nav__link">
      006-mysql的一些底层原理
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../数据库/005-ubuntu安装mysql没有让我设置密码/" title="005-ubuntu安装mysql没有让我设置密码" class="md-nav__link">
      005-ubuntu安装mysql没有让我设置密码
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../数据库/004-mysql-高级/" title="004-mysql-高级" class="md-nav__link">
      004-mysql-高级
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../数据库/003-黑马-mysql-下/" title="003-黑马-mysql-下" class="md-nav__link">
      003-黑马-mysql-下
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../数据库/002-黑马mysql-上/" title="002-黑马mysql-上" class="md-nav__link">
      002-黑马mysql-上
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../数据库/001-mysql的使用/" title="001-mysql的使用" class="md-nav__link">
      001-mysql的使用
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

    
      
      
      


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-11" type="checkbox" id="nav-11">
    
    <label class="md-nav__link" for="nav-11">
      windows10系统使用
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="1">
      <label class="md-nav__title" for="nav-11">
        windows10系统使用
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../../windows10系统使用/028 win10电脑无线wifi总是掉线断网怎么解决/" title="028 win10电脑无线wifi总是掉线断网怎么解决" class="md-nav__link">
      028 win10电脑无线wifi总是掉线断网怎么解决
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../windows10系统使用/027 远程时的不设置密码以及修改设置后使用空密码登录/" title="027 远程时的不设置密码以及修改设置后使用空密码登录" class="md-nav__link">
      027 远程时的不设置密码以及修改设置后使用空密码登录
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../windows10系统使用/026 windows系统如何查看端口被占用、杀进程/" title="026 windows系统如何查看端口被占用、杀进程" class="md-nav__link">
      026 windows系统如何查看端口被占用、杀进程
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../windows10系统使用/025 解决SVN安装语言包后无法选择中文的问题/" title="025 解决SVN安装语言包后无法选择中文的问题" class="md-nav__link">
      025 解决SVN安装语言包后无法选择中文的问题
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../windows10系统使用/025 docker安装/" title="025 docker安装" class="md-nav__link">
      025 docker安装
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../windows10系统使用/024 如何在开始菜单隐藏关机按钮/" title="024 如何在开始菜单隐藏关机按钮" class="md-nav__link">
      024 如何在开始菜单隐藏关机按钮
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../windows10系统使用/023 windows 命令行代码提示/" title="023 windows 命令行代码提示" class="md-nav__link">
      023 windows 命令行代码提示
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../windows10系统使用/022-Vmware安装报错--此安装程序要求您重新启动系统以完成Microsoft-VC-Redistributable-安装/" title="022-Vmware安装报错--此安装程序要求您重新启动系统以完成Microsoft-VC-Redistributable-安装" class="md-nav__link">
      022-Vmware安装报错--此安装程序要求您重新启动系统以完成Microsoft-VC-Redistributable-安装
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../windows10系统使用/021win系统新增新建右键Markdown文件及默认UTF-8编码格式/" title="021win系统新增新建右键Markdown文件及默认UTF-8编码格式" class="md-nav__link">
      021win系统新增新建右键Markdown文件及默认UTF-8编码格式
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../windows10系统使用/020-删除关机等按钮/" title="020-删除关机等按钮" class="md-nav__link">
      020-删除关机等按钮
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../windows10系统使用/019-windows1809-系统最近的更新出现了bug/" title="019-windows1809-系统最近的更新出现了bug" class="md-nav__link">
      019-windows1809-系统最近的更新出现了bug
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../windows10系统使用/018--win10卸载自带的应用/" title="018--win10卸载自带的应用" class="md-nav__link">
      018--win10卸载自带的应用
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../windows10系统使用/017-笔记本软件/" title="017-笔记本软件" class="md-nav__link">
      017-笔记本软件
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../windows10系统使用/016-Java添加环境变量/" title="016-Java添加环境变量" class="md-nav__link">
      016-Java添加环境变量
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../windows10系统使用/015-anaconda-添加环境变量/" title="015-anaconda-添加环境变量" class="md-nav__link">
      015-anaconda-添加环境变量
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../windows10系统使用/014-Win10添加右键打开cmd和Powershell窗口（管理员-非管理员）/" title="014-Win10添加右键打开cmd和Powershell窗口（管理员-非管理员）" class="md-nav__link">
      014-Win10添加右键打开cmd和Powershell窗口（管理员-非管理员）
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../windows10系统使用/013-win10取消应用弹框/" title="013-win10取消应用弹框" class="md-nav__link">
      013-win10取消应用弹框
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../windows10系统使用/012--win10系统怎么禁用defender/" title="012--win10系统怎么禁用defender" class="md-nav__link">
      012--win10系统怎么禁用defender
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../windows10系统使用/011-Windows-无法启动print-spooler服务(位于本地计算机上)。错误0x800706b/" title="011-Windows-无法启动print-spooler服务(位于本地计算机上)。错误0x800706b" class="md-nav__link">
      011-Windows-无法启动print-spooler服务(位于本地计算机上)。错误0x800706b
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../windows10系统使用/010-Axmath破解安装使用/" title="010-Axmath破解安装使用" class="md-nav__link">
      010-Axmath破解安装使用
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../windows10系统使用/007-Mathpix-Snipping-Tool-+-Typora-+-Pandoc-快速将其他论文中的公式图片转化成Word可编辑格式/" title="007-Mathpix-Snipping-Tool-+-Typora-+-Pandoc-快速将其他论文中的公式图片转化成Word可编辑格式" class="md-nav__link">
      007-Mathpix-Snipping-Tool-+-Typora-+-Pandoc-快速将其他论文中的公式图片转化成Word可编辑格式
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../windows10系统使用/006-picgo图床使用/" title="006-picgo图床使用" class="md-nav__link">
      006-picgo图床使用
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../windows10系统使用/005-win10开机提示用户名和密码不正确的解决办法/" title="005-win10开机提示用户名和密码不正确的解决办法" class="md-nav__link">
      005-win10开机提示用户名和密码不正确的解决办法
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../windows10系统使用/004-windows下安装pandoc并通过Typora导出pdf和word/" title="004-windows下安装pandoc并通过Typora导出pdf和word" class="md-nav__link">
      004-windows下安装pandoc并通过Typora导出pdf和word
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../windows10系统使用/002-几何画板迷你增强版/" title="002-几何画板迷你增强版" class="md-nav__link">
      002-几何画板迷你增强版
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../windows10系统使用/001-开机启动项的存储位置/" title="001-开机启动项的存储位置" class="md-nav__link">
      001-开机启动项的存储位置
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

    
      
      
      


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-12" type="checkbox" id="nav-12">
    
    <label class="md-nav__link" for="nav-12">
      ubuntu系统的使用
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="1">
      <label class="md-nav__title" for="nav-12">
        ubuntu系统的使用
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../../ubuntu系统的使用/054 ubuntu18.04VNC远程配置/" title="054 ubuntu18.04VNC远程配置" class="md-nav__link">
      054 ubuntu18.04VNC远程配置
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../ubuntu系统的使用/053-ubuntu18-04安装搜狗输入法/" title="053 ubuntu18-04安装搜狗输入法" class="md-nav__link">
      053 ubuntu18-04安装搜狗输入法
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../ubuntu系统的使用/052-ubuntu18-04卸载ibus出现登录循环问题,真是什么人都出来写博客/" title="052 ubuntu18-04卸载ibus出现登录循环问题,真是什么人都出来写博客" class="md-nav__link">
      052 ubuntu18-04卸载ibus出现登录循环问题,真是什么人都出来写博客
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../ubuntu系统的使用/051-ubuntu安装redis的方法/" title="051 ubuntu安装redis的方法" class="md-nav__link">
      051 ubuntu安装redis的方法
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../ubuntu系统的使用/050-ubuntu下codeblocks安装及汉化教程/" title="050 ubuntu下codeblocks安装及汉化教程" class="md-nav__link">
      050 ubuntu下codeblocks安装及汉化教程
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../ubuntu系统的使用/049-ubuntu绘图软件/" title="049 ubuntu绘图软件" class="md-nav__link">
      049 ubuntu绘图软件
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../ubuntu系统的使用/048-linux的指令/" title="048 linux的指令" class="md-nav__link">
      048 linux的指令
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../ubuntu系统的使用/047-记录一次笔记本使用硬盘系统的经历/" title="047 记录一次笔记本使用硬盘系统的经历" class="md-nav__link">
      047 记录一次笔记本使用硬盘系统的经历
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../ubuntu系统的使用/044 linux系统/" title="044 linux系统" class="md-nav__link">
      044 linux系统
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../ubuntu系统的使用/043 ubuntu安装eclipse/" title="043 ubuntu安装eclipse" class="md-nav__link">
      043 ubuntu安装eclipse
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../ubuntu系统的使用/042 ubuntu在使用搜狗输入法时,spyder不能输入中文/" title="042 ubuntu在使用搜狗输入法时,spyder不能输入中文" class="md-nav__link">
      042 ubuntu在使用搜狗输入法时,spyder不能输入中文
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../ubuntu系统的使用/041-解决ubuntu鼠标灵敏度无法调整的情况/" title="041 解决ubuntu鼠标灵敏度无法调整的情况" class="md-nav__link">
      041 解决ubuntu鼠标灵敏度无法调整的情况
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../ubuntu系统的使用/040-解决Ubuntu屏幕分辨率不正常问题/" title="040 解决Ubuntu屏幕分辨率不正常问题" class="md-nav__link">
      040 解决Ubuntu屏幕分辨率不正常问题
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../ubuntu系统的使用/039-ubuntu安装latex+texstudio/" title="039 ubuntu安装latex+texstudio" class="md-nav__link">
      039 ubuntu安装latex+texstudio
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../ubuntu系统的使用/038-乌班图不能用QQ,微信怎么办-/" title="038 乌班图不能用QQ,微信怎么办-" class="md-nav__link">
      038 乌班图不能用QQ,微信怎么办-
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../ubuntu系统的使用/037-乌班图安装的网易云音乐不能正常启动怎么办-/" title="037 乌班图安装的网易云音乐不能正常启动怎么办-" class="md-nav__link">
      037 乌班图安装的网易云音乐不能正常启动怎么办-
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../ubuntu系统的使用/036-为火狐浏览器安装flash插件/" title="036 为火狐浏览器安装flash插件" class="md-nav__link">
      036 为火狐浏览器安装flash插件
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../ubuntu系统的使用/035-乌班图安装强大的终端-Terminator/" title="035 乌班图安装强大的终端-Terminator" class="md-nav__link">
      035 乌班图安装强大的终端-Terminator
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../ubuntu系统的使用/034-乌班图最好用的截图软件的安装/" title="034 乌班图最好用的截图软件的安装" class="md-nav__link">
      034 乌班图最好用的截图软件的安装
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../ubuntu系统的使用/033-乌班图下Anaconda环境的使用/" title="033 乌班图下Anaconda环境的使用" class="md-nav__link">
      033 乌班图下Anaconda环境的使用
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../ubuntu系统的使用/032-乌班图系统的原版优化配置/" title="032 乌班图系统的原版优化配置" class="md-nav__link">
      032 乌班图系统的原版优化配置
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../ubuntu系统的使用/031-乌班图安装虚拟机VMware/" title="031 乌班图安装虚拟机VMware" class="md-nav__link">
      031 乌班图安装虚拟机VMware
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../ubuntu系统的使用/030-乌班图自带输入法ibus-无法按数字键取词/" title="030 乌班图自带输入法ibus-无法按数字键取词" class="md-nav__link">
      030 乌班图自带输入法ibus-无法按数字键取词
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../ubuntu系统的使用/029-乌班图鼠标键盘延迟问题--已/" title="029 乌班图鼠标键盘延迟问题--已" class="md-nav__link">
      029 乌班图鼠标键盘延迟问题--已
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../ubuntu系统的使用/028-乌班图添加环境变量路径/" title="028 乌班图添加环境变量路径" class="md-nav__link">
      028 乌班图添加环境变量路径
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../ubuntu系统的使用/027-如何在Ubuntu中使用GNOME-Sushi快速预览文件/" title="027 如何在Ubuntu中使用GNOME-Sushi快速预览文件" class="md-nav__link">
      027 如何在Ubuntu中使用GNOME-Sushi快速预览文件
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../ubuntu系统的使用/026-Ubuntu18-04-问题——无法安全地用该源进行更新，所以默认禁用该源。/" title="026 Ubuntu18-04-问题——无法安全地用该源进行更新，所以默认禁用该源。" class="md-nav__link">
      026 Ubuntu18-04-问题——无法安全地用该源进行更新，所以默认禁用该源。
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../ubuntu系统的使用/025-在局域网内Ubuntu和Windows之间实现共享文件教程/" title="025 在局域网内Ubuntu和Windows之间实现共享文件教程" class="md-nav__link">
      025 在局域网内Ubuntu和Windows之间实现共享文件教程
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../ubuntu系统的使用/024-ubuntu系统下matplotlib中文乱码问题/" title="024 ubuntu系统下matplotlib中文乱码问题" class="md-nav__link">
      024 ubuntu系统下matplotlib中文乱码问题
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../ubuntu系统的使用/023-ubuntu安装anaconda/" title="023 ubuntu安装anaconda" class="md-nav__link">
      023 ubuntu安装anaconda
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../ubuntu系统的使用/022-乌班图常用指令/" title="022 乌班图常用指令" class="md-nav__link">
      022 乌班图常用指令
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../ubuntu系统的使用/021-ubuntu18-04实时显示网速CPU温度等/" title="021 ubuntu18-04实时显示网速CPU温度等" class="md-nav__link">
      021 ubuntu18-04实时显示网速CPU温度等
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../ubuntu系统的使用/020-ubuntu18-04智能拼音候选字体调节方法/" title="020 ubuntu18-04智能拼音候选字体调节方法" class="md-nav__link">
      020 ubuntu18-04智能拼音候选字体调节方法
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../ubuntu系统的使用/019-Ubuntu解压zip压缩包中文乱码/" title="019 Ubuntu解压zip压缩包中文乱码" class="md-nav__link">
      019 Ubuntu解压zip压缩包中文乱码
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../ubuntu系统的使用/018-Windows下安装Notepad++-以及-Ubuntu-16-04下-安装-Notepadqq/" title="018 Windows下安装Notepad++-以及-Ubuntu-16-04下-安装-Notepadqq" class="md-nav__link">
      018 Windows下安装Notepad++-以及-Ubuntu-16-04下-安装-Notepadqq
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../ubuntu系统的使用/017-ubuntu更新引导项/" title="017 ubuntu更新引导项" class="md-nav__link">
      017 ubuntu更新引导项
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../ubuntu系统的使用/016-ubuntu下NTFS分区无法访问解决/" title="016 ubuntu下NTFS分区无法访问解决" class="md-nav__link">
      016 ubuntu下NTFS分区无法访问解决
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../ubuntu系统的使用/015-保存ubuntu终端屏幕输出的信息/" title="015 保存ubuntu终端屏幕输出的信息" class="md-nav__link">
      015 保存ubuntu终端屏幕输出的信息
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../ubuntu系统的使用/014-在Ubuntu上安装Chrome浏览器和ChromeDriver/" title="014 在Ubuntu上安装Chrome浏览器和ChromeDriver" class="md-nav__link">
      014 在Ubuntu上安装Chrome浏览器和ChromeDriver
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../ubuntu系统的使用/013-Ubuntu下解决apt-update时签名无效问题/" title="013 Ubuntu下解决apt-update时签名无效问题" class="md-nav__link">
      013 Ubuntu下解决apt-update时签名无效问题
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../ubuntu系统的使用/012-ubuntu怎么切换到root用户,切换到root账号方法/" title="012 ubuntu怎么切换到root用户,切换到root账号方法" class="md-nav__link">
      012 ubuntu怎么切换到root用户,切换到root账号方法
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../ubuntu系统的使用/011-ubuntu安装makedown编辑器typora/" title="011 ubuntu安装makedown编辑器typora" class="md-nav__link">
      011 ubuntu安装makedown编辑器typora
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../ubuntu系统的使用/010ubuntu配置java开发环境/" title="010 ubuntu配置java开发环境" class="md-nav__link">
      010 ubuntu配置java开发环境
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../ubuntu系统的使用/009ubuntu安装remarkable-makedown编辑器/" title="009 ubuntu安装remarkable-makedown编辑器" class="md-nav__link">
      009 ubuntu安装remarkable-makedown编辑器
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../ubuntu系统的使用/008ubuntu-18-04如何自动更换壁纸？/" title="008 ubuntu-18-04如何自动更换壁纸？" class="md-nav__link">
      008 ubuntu-18-04如何自动更换壁纸？
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../ubuntu系统的使用/007Ubuntu-18-04-引导修复（boot-repair）/" title="007 Ubuntu-18-04-引导修复（boot-repair）" class="md-nav__link">
      007 Ubuntu-18-04-引导修复（boot-repair）
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../ubuntu系统的使用/006ubuntu18-04无法下载-http---dl-google-com-linux-chrome-deb-dists-stable-/" title="006 ubuntu18-04无法下载-http---dl-google-com-linux-chrome-deb-dists-stable-" class="md-nav__link">
      006 ubuntu18-04无法下载-http---dl-google-com-linux-chrome-deb-dists-stable-
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../ubuntu系统的使用/005ubuntu18-04安装xmind-8/" title="005 ubuntu18-04安装xmind-8" class="md-nav__link">
      005 ubuntu18-04安装xmind-8
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../ubuntu系统的使用/004ubuntu使用pandoc配合typora将makedown转换为docx/" title="004 ubuntu使用pandoc配合typora将makedown转换为docx" class="md-nav__link">
      004 ubuntu使用pandoc配合typora将makedown转换为docx
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../ubuntu系统的使用/003ubuntu安装mathpix/" title="003 ubuntu安装mathpix" class="md-nav__link">
      003 ubuntu安装mathpix
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../ubuntu系统的使用/002如何移植ubuntu系统到另一台电脑-/" title="002 如何移植ubuntu系统到另一台电脑-" class="md-nav__link">
      002 如何移植ubuntu系统到另一台电脑-
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../ubuntu系统的使用/001tplink无线网卡在ubuntu-16-04-下频繁掉线-信号弱-解决办法/" title="001 tplink无线网卡在ubuntu-16-04-下频繁掉线-信号弱-解决办法" class="md-nav__link">
      001 tplink无线网卡在ubuntu-16-04-下频繁掉线-信号弱-解决办法
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

    
      
      
      


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-13" type="checkbox" id="nav-13">
    
    <label class="md-nav__link" for="nav-13">
      未分类
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="1">
      <label class="md-nav__title" for="nav-13">
        未分类
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../../未分类/010 ssh远程链接服务器，避免因断网而中断训练方法/" title="010 ssh远程链接服务器，避免因断网而中断训练方法" class="md-nav__link">
      010 ssh远程链接服务器，避免因断网而中断训练方法
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../未分类/009 git忽略本地修改更新远程仓库内容到本地/" title="009 git忽略本地修改更新远程仓库内容到本地" class="md-nav__link">
      009 git忽略本地修改更新远程仓库内容到本地
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../未分类/008 编程注意小技巧/" title="008 编程注意小技巧" class="md-nav__link">
      008 编程注意小技巧
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../未分类/007 操作系统词典/" title="007 操作系统词典" class="md-nav__link">
      007 操作系统词典
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../未分类/006 sublime text 3 显示空格和Tab/" title="006 sublime text 3 显示空格和Tab" class="md-nav__link">
      006 sublime text 3 显示空格和Tab
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../未分类/005 GitBook 搭建使用教程/" title="005 GitBook 搭建使用教程" class="md-nav__link">
      005 GitBook 搭建使用教程
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../未分类/004 ffmpeg的小使用/" title="004 ffmpeg的小使用" class="md-nav__link">
      004 ffmpeg的小使用
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../未分类/003 超详细教程：YOLO_V3（yolov3）训练自己的数据/" title="003 超详细教程：YOLO_V3（yolov3）训练自己的数据" class="md-nav__link">
      003 超详细教程：YOLO_V3（yolov3）训练自己的数据
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../未分类/002 加速国内Github访问/" title="002 加速国内Github访问" class="md-nav__link">
      002 加速国内Github访问
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../未分类/001 git的使用/" title="001 git的使用" class="md-nav__link">
      001 git的使用
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              <div class="md-sidebar md-sidebar--secondary" data-md-component="toc">
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    
<nav class="md-nav md-nav--secondary">
  
  
    
  
  
    <label class="md-nav__title" for="__toc">目录</label>
    <ul class="md-nav__list" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#_1" class="md-nav__link">
    分类 编程技术
  </a>
  
</li>
      
      
      
      
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          <div class="md-content">
            <article class="md-content__inner md-typeset">
              
                
                
                <h2 id="scrapy">Scrapy 入门教程(菜鸟教程)<a class="headerlink" href="#scrapy" title="Permanent link">&para;</a></h2>
<h3 id="_1"><em>分类</em> <a href="https://www.runoob.com/w3cnote_genre/code">编程技术</a><a class="headerlink" href="#_1" title="Permanent link">&para;</a></h3>
<p>Scrapy 是用 Python 实现的一个为了爬取网站数据、提取结构性数据而编写的应用框架。</p>
<p>Scrapy 常应用在包括数据挖掘，信息处理或存储历史数据等一系列的程序中。</p>
<p>通常我们可以很简单的通过 Scrapy 框架实现一个爬虫，抓取指定网站的内容或图片。</p>
<hr />
<h2 id="scrapy_1">Scrapy架构图(绿线是数据流向)<a class="headerlink" href="#scrapy_1" title="Permanent link">&para;</a></h2>
<p><img alt="img" src="../024 scrapy爬虫框架.image/8c591d54457bb033812a2b0364011e9c_articlex.png" /></p>
<ul>
<li><strong>Scrapy Engine(引擎)</strong>: 负责Spider、ItemPipeline、Downloader、Scheduler中间的通讯，信号、数据传递等。</li>
<li><strong>Scheduler(调度器)</strong>: 它负责接受引擎发送过来的Request请求，并按照一定的方式进行整理排列，入队，当引擎需要时，交还给引擎。</li>
<li><strong>Downloader（下载器）</strong>：负责下载Scrapy Engine(引擎)发送的所有Requests请求，并将其获取到的Responses交还给Scrapy Engine(引擎)，由引擎交给Spider来处理，</li>
<li><strong>Spider（爬虫）</strong>：它负责处理所有Responses,从中分析提取数据，获取Item字段需要的数据，并将需要跟进的URL提交给引擎，再次进入Scheduler(调度器).</li>
<li><strong>Item Pipeline(管道)</strong>：它负责处理Spider中获取到的Item，并进行进行后期处理（详细分析、过滤、存储等）的地方。</li>
<li><strong>Downloader Middlewares（下载中间件）</strong>：你可以当作是一个可以自定义扩展下载功能的组件。</li>
<li><strong>Spider Middlewares（Spider中间件）</strong>：你可以理解为是一个可以自定扩展和操作引擎和Spider中间通信的功能组件（比如进入Spider的Responses;和从Spider出去的Requests）</li>
</ul>
<h2 id="scrapy_2">Scrapy的运作流程<a class="headerlink" href="#scrapy_2" title="Permanent link">&para;</a></h2>
<p>代码写好，程序开始运行...</p>
<ul>
<li>1 引擎：Hi！Spider, 你要处理哪一个网站？</li>
<li>2 Spider：老大要我处理xxxx.com。</li>
<li>3 引擎：你把第一个需要处理的URL给我吧。</li>
<li>4 Spider：给你，第一个URL是xxxxxxx.com。</li>
<li>5 引擎：Hi！调度器，我这有request请求你帮我排序入队一下。</li>
<li>6 调度器：好的，正在处理你等一下。</li>
<li>7 引擎：Hi！调度器，把你处理好的request请求给我。</li>
<li>8 调度器：给你，这是我处理好的request</li>
<li>9 引擎：Hi！下载器，你按照老大的下载中间件的设置帮我下载一下这个request请求</li>
<li>10 下载器：好的！给你，这是下载好的东西。（如果失败：sorry，这个request下载失败了。然后引擎告诉调度器，这个request下载失败了，你记录一下，我们待会儿再下载）</li>
<li>11 引擎：Hi！Spider，这是下载好的东西，并且已经按照老大的下载中间件处理过了，你自己处理一下（注意！这儿responses默认是交给def parse()这个函数处理的）</li>
<li>12 Spider：（处理完毕数据之后对于需要跟进的URL），Hi！引擎，我这里有两个结果，这个是我需要跟进的URL，还有这个是我获取到的Item数据。</li>
<li>13 引擎：Hi ！管道 我这儿有个item你帮我处理一下！调度器！这是需要跟进URL你帮我处理下。然后从第四步开始循环，直到获取完老大需要全部信息。</li>
<li>14 管道调度器：好的，现在就做！</li>
</ul>
<p><strong>注意！只有当调度器中不存在任何request了，整个程序才会停止，（也就是说，对于下载失败的URL，Scrapy也会重新下载。）</strong></p>
<hr />
<h2 id="scrapy-4">制作 Scrapy 爬虫 一共需要4步：<a class="headerlink" href="#scrapy-4" title="Permanent link">&para;</a></h2>
<ol>
<li>新建项目 (scrapy startproject xxx)：新建一个新的爬虫项目</li>
<li>明确目标 （编写items.py）：明确你想要抓取的目标</li>
<li>制作爬虫 （spiders/xxspider.py）：制作爬虫开始爬取网页</li>
<li>存储内容 （pipelines.py）：设计管道存储爬取内容</li>
</ol>
<hr />
<h2 id="_2">安装<a class="headerlink" href="#_2" title="Permanent link">&para;</a></h2>
<h3 id="windows">Windows 安装方式<a class="headerlink" href="#windows" title="Permanent link">&para;</a></h3>
<p>升级 pip 版本：</p>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1</pre></div></td><td class="code"><div class="codehilite"><pre><span></span>pip install --upgrade pip
</pre></div>
</td></tr></table>

<p>通过 pip 安装 Scrapy 框架:</p>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1</pre></div></td><td class="code"><div class="codehilite"><pre><span></span>pip install Scrapy
</pre></div>
</td></tr></table>

<h3 id="ubuntu">Ubuntu 安装方式<a class="headerlink" href="#ubuntu" title="Permanent link">&para;</a></h3>
<p>安装非 Python 的依赖:</p>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1</pre></div></td><td class="code"><div class="codehilite"><pre><span></span>sudo apt-get install python-dev python-pip libxml2-dev libxslt1-dev zlib1g-dev libffi-dev libssl-dev
</pre></div>
</td></tr></table>

<p>通过 pip 安装 Scrapy 框架：</p>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1</pre></div></td><td class="code"><div class="codehilite"><pre><span></span>sudo pip install scrapy
</pre></div>
</td></tr></table>

<h3 id="mac-os">Mac OS 安装方式<a class="headerlink" href="#mac-os" title="Permanent link">&para;</a></h3>
<p>对于Mac OS系统来说，由于系统本身会引用自带的python2.x的库，因此默认安装的包是不能被删除的，但是你用python2.x来安装Scrapy会报错，用python3.x来安装也是报错，我最终没有找到直接安装Scrapy的方法，所以我用另一种安装方式来说一下安装步骤，解决的方式是就是使用virtualenv来安装。</p>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1
2
3
4
5</pre></div></td><td class="code"><div class="codehilite"><pre><span></span>$ sudo pip install virtualenv
$ virtualenv scrapyenv
$ cd scrapyenv
$ source bin/activate
$ pip install Scrapy
</pre></div>
</td></tr></table>

<p>安装后，只要在命令终端输入 scrapy，提示类似以下结果，代表已经安装成功。</p>
<p><img alt="img" src="../024 scrapy爬虫框架.image/3748346984-5a79c47d84aba_articlex.png" /></p>
<hr />
<h2 id="_3">入门案例<a class="headerlink" href="#_3" title="Permanent link">&para;</a></h2>
<h3 id="_4">学习目标<a class="headerlink" href="#_4" title="Permanent link">&para;</a></h3>
<ul>
<li>创建一个Scrapy项目</li>
<li>定义提取的结构化数据(Item)</li>
<li>编写爬取网站的 Spider 并提取出结构化数据(Item)</li>
<li>编写 Item Pipelines 来存储提取到的Item(即结构化数据)</li>
</ul>
<h3 id="scrapy-startproject">一. 新建项目(scrapy startproject)<a class="headerlink" href="#scrapy-startproject" title="Permanent link">&para;</a></h3>
<p>在开始爬取之前，必须创建一个新的Scrapy项目。进入自定义的项目目录中，运行下列命令：</p>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1</pre></div></td><td class="code"><div class="codehilite"><pre><span></span>scrapy startproject mySpider
</pre></div>
</td></tr></table>

<p>其中， mySpider 为项目名称，可以看到将会创建一个 mySpider 文件夹，目录结构大致如下：</p>
<p>下面来简单介绍一下各个主要文件的作用：</p>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre> 1
 2
 3
 4
 5
 6
 7
 8
 9
10</pre></div></td><td class="code"><div class="codehilite"><pre><span></span>mySpider/
    scrapy.cfg
    mySpider/
        __init__.py
        items.py
        pipelines.py
        settings.py
        spiders/
            __init__.py
            ...
</pre></div>
</td></tr></table>

<p>这些文件分别是:</p>
<ul>
<li>scrapy.cfg: 项目的配置文件。</li>
<li>mySpider/: 项目的Python模块，将会从这里引用代码。</li>
<li>mySpider/items.py: 项目的目标文件。</li>
<li>mySpider/pipelines.py: 项目的管道文件。</li>
<li>mySpider/settings.py: 项目的设置文件。</li>
<li>mySpider/spiders/: 存储爬虫代码目录。</li>
</ul>
<h3 id="myspideritemspy">二、明确目标(mySpider/items.py)<a class="headerlink" href="#myspideritemspy" title="Permanent link">&para;</a></h3>
<p>我们打算抓取 <strong><a href="http://www.itcast.cn/channel/teacher.shtml">http://www.itcast.cn/channel/teacher.shtml</a></strong> 网站里的所有讲师的姓名、职称和个人信息。</p>
<ol>
<li>打开 mySpider 目录下的 items.py。</li>
<li>Item 定义结构化数据字段，用来保存爬取到的数据，有点像 Python 中的 dict，但是提供了一些额外的保护减少错误。</li>
<li>可以通过创建一个 scrapy.Item 类， 并且定义类型为 scrapy.Field 的类属性来定义一个 Item（可以理解成类似于 ORM 的映射关系）。</li>
<li>
<p>接下来，创建一个 ItcastItem 类，和构建 item 模型（model）。</p>
</li>
<li>
<p>```
    import scrapy</p>
<p>class ItcastItem(scrapy.Item):
   name = scrapy.Field()
   title = scrapy.Field()
   info = scrapy.Field()
```</p>
</li>
</ol>
<h3 id="spidersitcastspiderpy">三、制作爬虫 （spiders/itcastSpider.py）<a class="headerlink" href="#spidersitcastspiderpy" title="Permanent link">&para;</a></h3>
<p>爬虫功能要分两步：</p>
<p><strong>1. 爬数据</strong></p>
<p>在当前目录下输入命令，将在mySpider/spider目录下创建一个名为itcast的爬虫，并指定爬取域的范围：</p>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1</pre></div></td><td class="code"><div class="codehilite"><pre><span></span>scrapy genspider itcast &quot;itcast.cn&quot;
</pre></div>
</td></tr></table>

<p>打开 mySpider/spider目录里的 itcast.py，默认增加了下列代码:</p>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11</pre></div></td><td class="code"><div class="codehilite"><pre><span></span>import scrapy

class ItcastSpider(scrapy.Spider):
    name = &quot;itcast&quot;
    allowed_domains = [&quot;itcast.cn&quot;]
    start_urls = (
        &#39;http://www.itcast.cn/&#39;,
    )

    def parse(self, response):
        pass
</pre></div>
</td></tr></table>

<p>其实也可以由我们自行创建itcast.py并编写上面的代码，只不过使用命令可以免去编写固定代码的麻烦</p>
<p>要建立一个Spider， 你必须用scrapy.Spider类创建一个子类，并确定了三个强制的属性 和 一个方法。</p>
<p>name = "" ：这个爬虫的识别名称，必须是唯一的，在不同的爬虫必须定义不同的名字。</p>
<p>allow_domains = [] 是搜索的域名范围，也就是爬虫的约束区域，规定爬虫只爬取这个域名下的网页，不存在的URL会被忽略。</p>
<p>start_urls = () ：爬取的URL元祖/列表。爬虫从这里开始抓取数据，所以，第一次下载的数据将会从这些urls开始。其他子URL将会从这些起始URL中继承性生成。</p>
<p>parse(self, response) ：解析的方法，每个初始URL完成下载后将被调用，调用的时候传入从每一个URL传回的Response对象来作为唯一参数，主要作用如下：</p>
<p>负责解析返回的网页数据(response.body)，提取结构化数据(生成item)
生成需要下一页的URL请求。
将start_urls的值修改为需要爬取的第一个url</p>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1</pre></div></td><td class="code"><div class="codehilite"><pre><span></span>start_urls = (&quot;http://www.itcast.cn/channel/teacher.shtml&quot;,)
</pre></div>
</td></tr></table>

<p>修改parse()方法</p>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1
2
3</pre></div></td><td class="code"><div class="codehilite"><pre><span></span>def parse(self, response):
    filename = &quot;teacher.html&quot;
    open(filename, &#39;w&#39;).write(response.body)
</pre></div>
</td></tr></table>

<p>然后运行一下看看，在mySpider目录下执行：</p>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1</pre></div></td><td class="code"><div class="codehilite"><pre><span></span>scrapy crawl itcast
</pre></div>
</td></tr></table>

<p>是的，就是 itcast，看上面代码，它是 ItcastSpider 类的 name 属性，也就是使用 scrapy genspider命令的唯一爬虫名。</p>
<p>运行之后，如果打印的日志出现 [scrapy] INFO: Spider closed (finished)，代表执行完成。 之后当前文件夹中就出现了一个 teacher.html 文件，里面就是我们刚刚要爬取的网页的全部源代码信息。</p>
<p><strong>注意:</strong> Python2.x默认编码环境是ASCII，当和取回的数据编码格式不一致时，可能会造成乱码；我们可以指定保存内容的编码格式，一般情况下，我们可以在代码最上方添加</p>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1
2
3</pre></div></td><td class="code"><div class="codehilite"><pre><span></span>import sys
reload(sys)
sys.setdefaultencoding(&quot;utf-8&quot;)
</pre></div>
</td></tr></table>

<p>这三行代码是 Python2.x 里解决中文编码的万能钥匙，经过这么多年的吐槽后 Python3 学乖了，默认编码是Unicode了...(祝大家早日拥抱Python3)</p>
<p><strong>2. 取数据</strong></p>
<p>爬取整个网页完毕，接下来的就是的取过程了，首先观察页面源码：</p>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1
2
3
4</pre></div></td><td class="code"><div class="codehilite"><pre><span></span>&lt;div class=&quot;li_txt&quot;&gt;
    &lt;h3&gt;  xxx  &lt;/h3&gt;
    &lt;h4&gt; xxxxx &lt;/h4&gt;
    &lt;p&gt; xxxxxxxx &lt;/p&gt;
</pre></div>
</td></tr></table>

<p>是不是一目了然？直接上 XPath 开始提取数据吧。</p>
<p>xpath 方法，我们只需要输入的 xpath 规则就可以定位到相应 html 标签节点，详细内容可以查看 <a href="https://www.runoob.com/xpath/xpath-tutorial.html">xpath 教程</a>。</p>
<p>不会 xpath 语法没关系，Chrome 给我们提供了一键获取 xpath 地址的方法（<strong>右键-&gt;检查-&gt;copy-&gt;copy xpath</strong>）,如下图:</p>
<p><img alt="img" src="../024 scrapy爬虫框架.image/xpath-chrome.jpg" /></p>
<p>这里给出一些 XPath 表达式的例子及对应的含义:</p>
<ul>
<li><code>/html/head/title</code>: 选择HTML文档中 <code>&lt;head&gt;</code> 标签内的 <code>&lt;title&gt;</code> 元素</li>
<li><code>/html/head/title/text()</code>: 选择上面提到的 <code>&lt;title&gt;</code> 元素的文字</li>
<li><code>//td</code>: 选择所有的 <code>&lt;td&gt;</code> 元素</li>
<li><code>//div[@class="mine"]</code>: 选择所有具有 <code>class="mine"</code> 属性的 <code>div</code> 元素</li>
</ul>
<p>举例我们读取网站 <strong><a href="http://www.itcast.cn/">http://www.itcast.cn/</a></strong> 的网站标题，修改 itcast.py 文件代码如下：：</p>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17
18
19
20
21</pre></div></td><td class="code"><div class="codehilite"><pre><span></span># -*- coding: utf-8 -*-
import scrapy

# 以下三行是在 Python2.x版本中解决乱码问题，Python3.x 版本的可以去掉
import sys
reload(sys)
sys.setdefaultencoding(&quot;utf-8&quot;)

class Opp2Spider(scrapy.Spider):
    name = &#39;itcast&#39;
    allowed_domains = [&#39;itcast.com&#39;]
    start_urls = [&#39;http://www.itcast.cn/&#39;]

    def parse(self, response):
        # 获取网站标题
        context = response.xpath(&#39;/html/head/title/text()&#39;)   

        # 提取网站标题
        title = context.extract_first()  
        print(title) 
        pass
</pre></div>
</td></tr></table>

<p>执行以下命令：</p>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1
2
3
4
5
6</pre></div></td><td class="code"><div class="codehilite"><pre><span></span>$ scrapy crawl itcast
...
...
传智播客官网-好口碑IT培训机构,一样的教育,不一样的品质
...
...
</pre></div>
</td></tr></table>

<p>我们之前在 mySpider/items.py 里定义了一个 ItcastItem 类。 这里引入进来:</p>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1</pre></div></td><td class="code"><div class="codehilite"><pre><span></span>from mySpider.items import ItcastItem
</pre></div>
</td></tr></table>

<p>然后将我们得到的数据封装到一个 ItcastItem 对象中，可以保存每个老师的属性：</p>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25</pre></div></td><td class="code"><div class="codehilite"><pre><span></span>from mySpider.items import ItcastItem

def parse(self, response):
    #open(&quot;teacher.html&quot;,&quot;wb&quot;).write(response.body).close()

    # 存放老师信息的集合
    items = []

    for each in response.xpath(&quot;//div[@class=&#39;li_txt&#39;]&quot;):
        # 将我们得到的数据封装到一个 `ItcastItem` 对象
        item = ItcastItem()
        #extract()方法返回的都是unicode字符串
        name = each.xpath(&quot;h3/text()&quot;).extract()
        title = each.xpath(&quot;h4/text()&quot;).extract()
        info = each.xpath(&quot;p/text()&quot;).extract()

        #xpath返回的是包含一个元素的列表
        item[&#39;name&#39;] = name[0]
        item[&#39;title&#39;] = title[0]
        item[&#39;info&#39;] = info[0]

        items.append(item)

    # 直接返回最后数据
    return items
</pre></div>
</td></tr></table>

<p>我们暂时先不处理管道，后面会详细介绍。</p>
<h3 id="_5">保存数据<a class="headerlink" href="#_5" title="Permanent link">&para;</a></h3>
<p>scrapy保存信息的最简单的方法主要有四种，-o 输出指定格式的文件，命令如下：</p>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1</pre></div></td><td class="code"><div class="codehilite"><pre><span></span>scrapy crawl itcast -o teachers.json
</pre></div>
</td></tr></table>

<p>json lines格式，默认为Unicode编码</p>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1</pre></div></td><td class="code"><div class="codehilite"><pre><span></span>scrapy crawl itcast -o teachers.jsonl
</pre></div>
</td></tr></table>

<p>csv 逗号表达式，可用Excel打开</p>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1</pre></div></td><td class="code"><div class="codehilite"><pre><span></span>scrapy crawl itcast -o teachers.csv
</pre></div>
</td></tr></table>

<p>xml格式</p>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1</pre></div></td><td class="code"><div class="codehilite"><pre><span></span>scrapy crawl itcast -o teachers.xml
</pre></div>
</td></tr></table>

<h3 id="_6">思考<a class="headerlink" href="#_6" title="Permanent link">&para;</a></h3>
<p>如果将代码改成下面形式，结果完全一样。</p>
<p>请思考 yield 在这里的作用(<a href="https://www.runoob.com/w3cnote/python-yield-used-analysis.html">Python yield 使用浅析</a>)：</p>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37</pre></div></td><td class="code"><div class="codehilite"><pre><span></span># -*- coding: utf-8 -*-
import scrapy
from mySpider.items import ItcastItem

# 以下三行是在 Python2.x版本中解决乱码问题，Python3.x 版本的可以去掉
import sys
reload(sys)
sys.setdefaultencoding(&quot;utf-8&quot;)

class Opp2Spider(scrapy.Spider):
    name = &#39;itcast&#39;
    allowed_domains = [&#39;itcast.com&#39;]
    start_urls = (&quot;http://www.itcast.cn/channel/teacher.shtml&quot;,)

    def parse(self, response):
        #open(&quot;teacher.html&quot;,&quot;wb&quot;).write(response.body).close()

        # 存放老师信息的集合
        items = []

        for each in response.xpath(&quot;//div[@class=&#39;li_txt&#39;]&quot;):
            # 将我们得到的数据封装到一个 `ItcastItem` 对象
            item = ItcastItem()
            #extract()方法返回的都是unicode字符串
            name = each.xpath(&quot;h3/text()&quot;).extract()
            title = each.xpath(&quot;h4/text()&quot;).extract()
            info = each.xpath(&quot;p/text()&quot;).extract()

            #xpath返回的是包含一个元素的列表
            item[&#39;name&#39;] = name[0]
            item[&#39;title&#39;] = title[0]
            item[&#39;info&#39;] = info[0]

            items.append(item)

        # 直接返回最后数据
        return items
</pre></div>
</td></tr></table>

<blockquote>
<p>原文链接：<a href="https://segmentfault.com/a/1190000013178839">https://segmentfault.com/a/1190000013178839</a></p>
</blockquote>
<p><img alt="img" src="https://sponsor.segmentfault.com/lg.php?bannerid=333&amp;campaignid=14&amp;zoneid=25&amp;OASCAP=3&amp;loc=https%3A%2F%2Fsegmentfault.com%2Fa%2F1190000013199636&amp;referer=https%3A%2F%2Fsegmentfault.com%2Fu%2Frui0908%2Farticles%3Fpage%3D3&amp;cb=44d2403d86" /></p>
<h1 id="scrapy-shell">Scrapy Shell<a class="headerlink" href="#scrapy-shell" title="Permanent link">&para;</a></h1>
<p>Scrapy终端是一个交互终端，我们可以在未启动spider的情况下尝试及调试代码，也可以用来测试XPath或CSS表达式，查看他们的工作方式，方便我们爬取的网页中提取的数据。</p>
<p>如果安装了 IPython ，Scrapy终端将使用 IPython (替代标准Python终端)。 IPython 终端与其他相比更为强大，提供智能的自动补全，高亮输出，及其他特性。（推荐安装IPython）</p>
<h2 id="scrapy-shell_1">启动Scrapy Shell<a class="headerlink" href="#scrapy-shell_1" title="Permanent link">&para;</a></h2>
<p>进入项目的根目录，执行下列命令来启动shell:</p>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1</pre></div></td><td class="code"><div class="codehilite"><pre><span></span>scrapy shell &quot;http://www.itcast.cn/channel/teacher.shtml&quot;
</pre></div>
</td></tr></table>

<p>图片描述</p>
<p>Scrapy Shell根据下载的页面会自动创建一些方便使用的对象，例如 Response 对象，以及 Selector 对象 (对HTML及XML内容)。</p>
<ul>
<li>当shell载入后，将得到一个包含response数据的本地 response 变量，输入
    <code>response.body</code>将输出response的包体，输出 <code>response.headers</code> 可以看到response的包头。</li>
<li>输入 <code>response.selector</code> 时， 将获取到一个response 初始化的类 Selector 的对象，此时可以通过使用
    <code>response.selector.xpath()</code>或<code>response.selector.css()</code> 来对 response 进行查询。</li>
<li>Scrapy也提供了一些快捷方式, 例如 <code>response.xpath()</code>或<code>response.css()</code>同样可以生效（如之前的案例）。</li>
</ul>
<h2 id="selectors">Selectors选择器<a class="headerlink" href="#selectors" title="Permanent link">&para;</a></h2>
<p><strong>Scrapy Selectors 内置 XPath 和 CSS Selector 表达式机制</strong></p>
<p>Selector有四个基本的方法，最常用的还是xpath:</p>
<ul>
<li>xpath(): 传入xpath表达式，返回该表达式所对应的所有节点的selector list列表</li>
<li>extract(): 序列化该节点为Unicode字符串并返回list</li>
<li>css(): 传入CSS表达式，返回该表达式所对应的所有节点的selector list列表，语法同 BeautifulSoup4</li>
<li>re(): 根据传入的正则表达式对数据进行提取，返回Unicode字符串list列表</li>
</ul>
<h3 id="xpath">XPath表达式的例子及对应的含义:<a class="headerlink" href="#xpath" title="Permanent link">&para;</a></h3>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1
2
3
4</pre></div></td><td class="code"><div class="codehilite"><pre><span></span>/html/head/title: 选择&lt;HTML&gt;文档中 &lt;head&gt; 标签内的 &lt;title&gt; 元素
/html/head/title/text(): 选择上面提到的 &lt;title&gt; 元素的文字
//td: 选择所有的 &lt;td&gt; 元素
//div[@class=&quot;mine&quot;]: 选择所有具有 class=&quot;mine&quot; 属性的 div 元素
</pre></div>
</td></tr></table>

<h3 id="selector">尝试Selector<a class="headerlink" href="#selector" title="Permanent link">&para;</a></h3>
<p>我们用腾讯社招的网站<a href="http://hr.tencent.com/position.php?&amp;start=0#a">http://hr.tencent.com/positio...</a>举例：</p>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40</pre></div></td><td class="code"><div class="codehilite"><pre><span></span># 启动
scrapy shell &quot;http://hr.tencent.com/position.php?&amp;start=0#a&quot;

# 返回 xpath选择器对象列表
response.xpath(&#39;//title&#39;)
[&lt;Selector xpath=&#39;//title&#39; data=u&#39;&lt;title&gt;\u804c\u4f4d\u641c\u7d22 | \u793e\u4f1a\u62db\u8058 | Tencent \u817e\u8baf\u62db\u8058&lt;/title&#39;&gt;]

# 使用 extract()方法返回 Unicode字符串列表
response.xpath(&#39;//title&#39;).extract()
[u&#39;&lt;title&gt;\u804c\u4f4d\u641c\u7d22 | \u793e\u4f1a\u62db\u8058 | Tencent \u817e\u8baf\u62db\u8058&lt;/title&gt;&#39;]

# 打印列表第一个元素，终端编码格式显示
print response.xpath(&#39;//title&#39;).extract()[0]
&lt;title&gt;职位搜索 | 社会招聘 | Tencent 腾讯招聘&lt;/title&gt;

# 返回 xpath选择器对象列表
response.xpath(&#39;//title/text()&#39;)
&lt;Selector xpath=&#39;//title/text()&#39; data=u&#39;\u804c\u4f4d\u641c\u7d22 | \u793e\u4f1a\u62db\u8058 | Tencent \u817e\u8baf\u62db\u8058&#39;&gt;

# 返回列表第一个元素的Unicode字符串
response.xpath(&#39;//title/text()&#39;)[0].extract()
u&#39;\u804c\u4f4d\u641c\u7d22 | \u793e\u4f1a\u62db\u8058 | Tencent \u817e\u8baf\u62db\u8058&#39;

# 按终端编码格式显示
print response.xpath(&#39;//title/text()&#39;)[0].extract()
职位搜索 | 社会招聘 | Tencent 腾讯招聘

response.xpath(&#39;//*[@class=&quot;even&quot;]&#39;)
职位名称:

print site[0].xpath(&#39;./td[1]/a/text()&#39;).extract()[0]
TEG15-运营开发工程师（深圳）
职位名称详情页:

print site[0].xpath(&#39;./td[1]/a/@href&#39;).extract()[0]
position_detail.php?id=20744&amp;keywords=&amp;tid=0&amp;lid=0
职位类别:

print site[0].xpath(&#39;./td[2]/text()&#39;).extract()[0]
技术类
</pre></div>
</td></tr></table>

<p>以后做数据提取的时候，可以把现在Scrapy Shell中测试，测试通过后再应用到代码中。</p>
<p>当然Scrapy Shell作用不仅仅如此，但是不属于我们课程重点，不做详细介绍。</p>
<p>官方文档：[<a href="http://scrapy-chs.readthedocs.io/zh_CN/latest/topics/shell.html">http://scrapy-chs.readthedocs...</a></p>
<h1 id="item-pipeline">Item Pipeline<a class="headerlink" href="#item-pipeline" title="Permanent link">&para;</a></h1>
<p>当Item在Spider中被收集之后，它将会被传递到Item Pipeline，这些Item Pipeline组件按定义的顺序处理Item。</p>
<p>每个Item Pipeline都是实现了简单方法的Python类，比如决定此Item是丢弃而存储。以下是item pipeline的一些典型应用：</p>
<ul>
<li>验证爬取的数据(检查item包含某些字段，比如说name字段)</li>
<li>查重(并丢弃)</li>
<li>将爬取结果保存到文件或者数据库中</li>
</ul>
<h2 id="item-pipeline_1">编写item pipeline<a class="headerlink" href="#item-pipeline_1" title="Permanent link">&para;</a></h2>
<p>编写item pipeline很简单，item pipiline组件是一个独立的Python类，其中process_item()方法必须实现:</p>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17
18
19
20
21</pre></div></td><td class="code"><div class="codehilite"><pre><span></span>import something

class SomethingPipeline(object):
    def __init__(self):    
        # 可选实现，做参数初始化等
        # doing something

    def process_item(self, item, spider):
        # item (Item 对象) – 被爬取的item
        # spider (Spider 对象) – 爬取该item的spider
        # 这个方法必须实现，每个item pipeline组件都需要调用该方法，
        # 这个方法必须返回一个 Item 对象，被丢弃的item将不会被之后的pipeline组件所处理。
        return item

    def open_spider(self, spider):
        # spider (Spider 对象) – 被开启的spider
        # 可选实现，当spider被开启时，这个方法被调用。

    def close_spider(self, spider):
        # spider (Spider 对象) – 被关闭的spider
        # 可选实现，当spider被关闭时，这个方法被调用
</pre></div>
</td></tr></table>

<h3 id="item-pipeline_2">启用一个Item Pipeline组件<a class="headerlink" href="#item-pipeline_2" title="Permanent link">&para;</a></h3>
<p>为了启用Item Pipeline组件，必须将它的类添加到 settings.py文件ITEM_PIPELINES 配置，就像下面这个例子:</p>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1
2
3
4
5
6</pre></div></td><td class="code"><div class="codehilite"><pre><span></span># Configure item pipelines
# See http://scrapy.readthedocs.org/en/latest/topics/item-pipeline.html
ITEM_PIPELINES = {
    #&#39;mySpider.pipelines.SomePipeline&#39;: 300,
    &quot;mySpider.pipelines.ItcastJsonPipeline&quot;:300
}
</pre></div>
</td></tr></table>

<p>分配给每个类的整型值，确定了他们运行的顺序，item按数字从低到高的顺序，通过pipeline，通常将这些数字定义在0-1000范围内（0-1000随意设置，数值越低，组件的优先级越高）</p>
<h3 id="_7">重新启动爬虫<a class="headerlink" href="#_7" title="Permanent link">&para;</a></h3>
<p>将parse()方法改为入门简介中最后思考中的代码，然后执行下面的命令：</p>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1</pre></div></td><td class="code"><div class="codehilite"><pre><span></span>scrapy crawl itcast
</pre></div>
</td></tr></table>

<p>查看当前目录是否生成teacher.json</p>
<p><img alt="img" src="https://sponsor.segmentfault.com/lg.php?bannerid=0&amp;campaignid=0&amp;zoneid=25&amp;loc=https%3A%2F%2Fsegmentfault.com%2Fa%2F1190000013267962&amp;referer=https%3A%2F%2Fsegmentfault.com%2Fu%2Frui0908%2Farticles%3Fpage%3D3&amp;cb=81b61efe68" /></p>
<h1 id="settings">Settings<a class="headerlink" href="#settings" title="Permanent link">&para;</a></h1>
<p>Scrapy设置(settings)提供了定制Scrapy组件的方法。可以控制包括核心(core)，插件(extension)，pipeline及spider组件。比如 设置Json Pipeliine、LOG_LEVEL等。</p>
<p>参考文档：<a href="http://scrapy-chs.readthedocs.io/zh_CN/1.0/topics/settings.html#topics-settings-ref">http://scrapy-chs.readthedocs...</a></p>
<hr />
<h2 id="_8">内置设置参考手册<a class="headerlink" href="#_8" title="Permanent link">&para;</a></h2>
<ul>
<li>
<p><code>BOT_NAME</code></p>
<ul>
<li>默认: 'scrapybot'</li>
<li>当您使用 startproject 命令创建项目时其也被自动赋值。</li>
</ul>
</li>
<li>
<p><code>CONCURRENT_ITEMS</code></p>
<ul>
<li>默认: 100</li>
<li>Item Processor(即 Item Pipeline) 同时处理(每个response的)item的最大值。</li>
</ul>
</li>
<li>
<p><code>CONCURRENT_REQUESTS</code></p>
<ul>
<li>默认: 16</li>
<li>Scrapy downloader 并发请求(concurrent requests)的最大值。</li>
</ul>
</li>
<li>
<p><code>DEFAULT_REQUEST_HEADERS</code></p>
<ul>
<li>
<p>默认: 如下</p>
<p><code>{
     'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',
     'Accept-Language': 'en',
     }</code></p>
</li>
</ul>
</li>
</ul>
<p>​             Scrapy HTTP Request使用的默认header。</p>
<ul>
<li>
<p><code>DEPTH_LIMIT</code></p>
<ul>
<li>默认: 0</li>
<li>爬取网站最大允许的深度(depth)值。如果为0，则没有限制。</li>
</ul>
</li>
<li>
<p><code>DOWNLOAD_DELAY</code></p>
<ul>
<li>
<p>默认: 0</p>
</li>
<li>
<p>下载器在下载同一个网站下一个页面前需要等待的时间。该选项可以用来限制爬取速度， 减轻服务器压力。同时也支持小数:</p>
<p><code>DOWNLOAD_DELAY = 0.25 # 250 ms of delay</code></p>
</li>
<li>
<p>默认情况下，Scrapy在两个请求间不等待一个固定的值， 而是使用0.5到1.5之间的一个随机值 <code>DOWNLOAD_DELAY</code> 的结果作为等待间隔。</p>
</li>
</ul>
</li>
<li>
<p><code>DOWNLOAD_TIMEOUT</code></p>
<ul>
<li>默认: 180</li>
<li>下载器超时时间(单位: 秒)。</li>
</ul>
</li>
<li>
<p><code>ITEM_PIPELINES</code></p>
<ul>
<li>默认: {}</li>
<li>保存项目中启用的pipeline及其顺序的字典。该字典默认为空，值(value)任意，不过值(value)习惯设置在0-1000范围内，值越小优先级越高。</li>
</ul>
</li>
</ul>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1
2
3
4</pre></div></td><td class="code"><div class="codehilite"><pre><span></span>            ITEM_PIPELINES = {
            &#39;mySpider.pipelines.SomethingPipeline&#39;: 300,
            &#39;mySpider.pipelines.ItcastJsonPipeline&#39;: 800,
            }
</pre></div>
</td></tr></table>

<ul>
<li>
<p><code>LOG_ENABLED</code></p>
<ul>
<li>默认: True</li>
<li>是否启用logging。</li>
</ul>
</li>
<li>
<p><code>LOG_ENCODING</code></p>
<ul>
<li>默认: 'utf-8'</li>
<li>logging使用的编码。</li>
</ul>
</li>
<li>
<p><code>LOG_LEVEL</code></p>
<ul>
<li>默认: 'DEBUG'</li>
<li>log的最低级别。可选的级别有: CRITICAL、 ERROR、WARNING、INFO、DEBUG 。</li>
</ul>
</li>
<li>
<p><code>USER_AGENT</code></p>
<ul>
<li>默认: "Scrapy/VERSION (+<a href="http://scrapy.org/">http://scrapy.org</a>)"</li>
<li>爬取的默认User-Agent，除非被覆盖。</li>
</ul>
</li>
<li>
<p><code>PROXIES</code>： 代理设置</p>
<ul>
<li>
<p>示例：</p>
<p><code>PROXIES = [
      {'ip_port': '111.11.228.75:80', 'password': ''},
      {'ip_port': '120.198.243.22:80', 'password': ''},
      {'ip_port': '111.8.60.9:8123', 'password': ''},
      {'ip_port': '101.71.27.120:80', 'password': ''},
      {'ip_port': '122.96.59.104:80', 'password': ''},
      {'ip_port': '122.224.249.122:8088', 'password':''},
    ]</code></p>
</li>
</ul>
</li>
<li>
<p><code>COOKIES_ENABLED = False</code></p>
<ul>
<li>禁用Cookies</li>
</ul>
</li>
</ul>
<h1 id="scrapyscrapy">scrapy爬虫框架（一）：scrapy框架简介<a class="headerlink" href="#scrapyscrapy" title="Permanent link">&para;</a></h1>
<h2 id="scrapy_3"><strong>一、安装scrapy框架</strong><a class="headerlink" href="#scrapy_3" title="Permanent link">&para;</a></h2>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1
2</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="c1">#打开命令行输入如下命令：</span>
<span class="n">pip</span> <span class="n">install</span> <span class="n">scrapy</span>
</pre></div>
</td></tr></table>

<h2 id="scrapy_4"><strong>二、创建一个scrapy项目</strong><a class="headerlink" href="#scrapy_4" title="Permanent link">&para;</a></h2>
<p>安装完成后，python会自动将 scrapy命令添加到环境变量中去，这时我们就可以使用 scrapy命令来创建我们的第一个 scrapy项目了。</p>
<p>打开命令行，输入如下命令</p>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="n">scrapy</span> <span class="n">startproject</span> <span class="n">yourproject</span>
</pre></div>
</td></tr></table>

<p>这里的 <code>startproject</code> 命令将会在当前目录下创建一个 scrapy项目，后面跟着的参数是需要创建的项目的名称。</p>
<p>比如这里我们会创建一个名为 <code>yourproject</code> 的项目，项目结构如下：</p>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre> 1
 2
 3
 4
 5
 6
 7
 8
 9
10</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="n">yourproject</span><span class="o">/</span>
    <span class="n">scrapy</span><span class="o">.</span><span class="n">cfg</span>
    <span class="n">yourproject</span><span class="o">/</span>
        <span class="fm">__init__</span><span class="o">.</span><span class="n">py</span>
        <span class="n">items</span><span class="o">.</span><span class="n">py</span>
        <span class="n">pipelines</span><span class="o">.</span><span class="n">py</span>
        <span class="n">settings</span><span class="o">.</span><span class="n">py</span>
        <span class="n">spiders</span><span class="o">/</span>
            <span class="fm">__init__</span><span class="o">.</span><span class="n">py</span>
            <span class="o">...</span>
</pre></div>
</td></tr></table>

<p>这些文件分别是：</p>
<ul>
<li>scrapy.cfg: 项目的配置文件</li>
<li>yourproject/: 该项目的python模块。该项目的所有代码都在这个目录下</li>
<li>yourproject/items.py: 项目中的item文件，我们在这个文件里定义要爬取的数据，有点类似于 Django的 model。</li>
<li>yourproject/pipelines.py:项目中的pipelines文件（我把这个称为通道文件，意思就是数据处理的通道），对爬取到的数据进行处理（如：储存）</li>
<li>yourproject/settings.py: 项目的设置文件，设置全局变量的值、通道的开启和关闭以及多个通道和爬虫的执行优先级</li>
<li>yourproject/spiders/: 爬虫的主要逻辑都在这个文件夹里，包括页面请求、数据提取、反爬措施等。</li>
</ul>
<h1 id="scrapyscrapy_1">scrapy爬虫框架（二）：创建一个scrapy爬虫<a class="headerlink" href="#scrapyscrapy_1" title="Permanent link">&para;</a></h1>
<p>在创建新的scrapy爬虫之前，我们需要先了解一下创建一个scrapy爬虫的基本步骤</p>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="n">scrapy</span> <span class="n">startproject</span> <span class="n">douban</span>
</pre></div>
</td></tr></table>

<p><img alt="image-20200714153445972" src="../024 scrapy爬虫框架.image/image-20200714153445972.png" /></p>
<h2 id="douban"><strong>一、确定要爬取的数据</strong>(项目名douban)<a class="headerlink" href="#douban" title="Permanent link">&para;</a></h2>
<p>以爬取豆瓣电影数据为例：
 每部电影所要爬取的信息有：(在items.py中进行数据的配置)</p>
<ul>
<li>片名:《头号玩家》</li>
<li>导演: 史蒂文·斯皮尔伯格</li>
<li>编剧: 扎克·佩恩 / 恩斯特·克莱恩</li>
<li>主演: 泰伊·谢里丹 / 奥利维亚·库克 / 本·门德尔森 / 马克·里朗斯 / 丽娜·维特 / 更多...</li>
<li>类型: 动作 / 科幻 / 冒险</li>
</ul>
<p>所以items文件的代码如下：</p>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1
2
3
4
5
6
7
8</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="k">class</span> <span class="nc">DoubanItem</span><span class="p">(</span><span class="n">scrapy</span><span class="o">.</span><span class="n">Item</span><span class="p">):</span>
    <span class="c1"># define the fields for your item here like:</span>
    <span class="c1"># name = scrapy.Field()</span>
    <span class="n">movie_name</span> <span class="o">=</span> <span class="n">scrapy</span><span class="o">.</span><span class="n">Field</span><span class="p">()</span>  <span class="c1">#电影名</span>
    <span class="n">movie_dir</span> <span class="o">=</span> <span class="n">scrapy</span><span class="o">.</span><span class="n">Field</span><span class="p">()</span>  <span class="c1">#导演</span>
    <span class="n">movie_editors</span> <span class="o">=</span> <span class="n">scrapy</span><span class="o">.</span><span class="n">Field</span><span class="p">()</span> <span class="c1">#编剧</span>
    <span class="n">movie_actors</span> <span class="o">=</span> <span class="n">scrapy</span><span class="o">.</span><span class="n">Field</span><span class="p">()</span> <span class="c1">#主演</span>
    <span class="n">movie_type</span> <span class="o">=</span> <span class="n">scrapy</span><span class="o">.</span><span class="n">Field</span><span class="p">()</span> <span class="c1">#类型</span>
</pre></div>
</td></tr></table>

<h2 id="_9">二、爬取所需的信息<a class="headerlink" href="#_9" title="Permanent link">&para;</a></h2>
<p>确定了要爬取的信息后，就可以开始写爬虫的代码了。</p>
<p>首先，我们创建一个爬虫文件。</p>
<p>在命令行中输入如下命令（必须在爬虫项目的文件夹里）：</p>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1
2
3</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="nt">scrapy</span> <span class="nt">genspider</span> <span class="nt">spidername</span> <span class="s2">&quot;domain&quot;</span>
<span class="p">#</span><span class="nn">spidername是要创建的爬虫的名字</span><span class="err">，</span><span class="nt">必须是唯一的</span><span class="err">，</span><span class="nt">而且不能和爬虫项目名相同</span>
<span class="p">#</span><span class="nn">domain是要爬取的网站的</span> <span class="nt">host</span><span class="err">，</span><span class="nt">即你所要爬取的网站的域名</span><span class="o">,</span><span class="nt">如</span><span class="err">：</span><span class="nt">www</span><span class="p">.</span><span class="nc">baidu</span><span class="p">.</span><span class="nc">com</span>
</pre></div>
</td></tr></table>

<p>这里使用的是:</p>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="n">scrapy</span> <span class="n">genspider</span> <span class="n">movieInfoSpider</span> <span class="s2">&quot;movie.douban.com&quot;</span>
</pre></div>
</td></tr></table>

<p><img alt="image-20200714153625658" src="../024 scrapy爬虫框架.image/image-20200714153625658.png" /></p>
<p>创建好爬虫文件后，打开爬虫项目下的spiders文件夹，用编辑器打开我们刚刚创建的爬虫文件。</p>
<p>文件里已经定义好了start_urls，这是我们运行爬虫时要访问的链接。</p>
<p>注意这是一个列表，可以放入多个url。</p>
<p>当爬虫运行时就会一个一个地访问 start_urls里的链接，然后将返回的响应做为参数传递给 parse函数。</p>
<p>在 parse函数里，我们可以来对网页中的信息进行提取。</p>
<p>示例只爬取一个页面（头号玩家的详情页），代码如下：</p>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17
18
19
20
21
22</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="c1"># -*- coding: utf-8 -*-</span>
<span class="c1">#movieInfoSpider.py</span>
<span class="n">import</span> <span class="n">scrapy</span>
<span class="c1">#导入DouBanItem类</span>
<span class="n">from</span> <span class="n">douban</span><span class="o">.</span><span class="n">items</span> <span class="n">import</span> <span class="no">DoubanItem</span>

<span class="k">class</span> <span class="nc">MovieinfoSpider</span><span class="p">(</span><span class="n">scrapy</span><span class="o">.</span><span class="n">Spider</span><span class="p">):</span>
    <span class="nb">name</span> <span class="o">=</span> <span class="s1">&#39;movieInfo&#39;</span>
    <span class="n">allowed_domains</span> <span class="o">=</span> <span class="o">[</span><span class="s1">&#39;movie.douban.com&#39;</span><span class="o">]</span>
    <span class="n">start_urls</span> <span class="o">=</span> <span class="o">[</span><span class="s1">&#39;https://movie.douban.com/subject/4920389/?from=showing&#39;</span><span class="o">]</span>

    <span class="k">def</span> <span class="nf">parse</span><span class="p">(</span><span class="nb">self</span><span class="p">,</span> <span class="n">response</span><span class="p">):</span>
        <span class="c1">#创建DoubanItem类</span>
        <span class="n">item</span> <span class="o">=</span> <span class="no">DoubanItem</span><span class="p">()</span>

        <span class="n">item</span><span class="o">[</span><span class="s1">&#39;movie_name&#39;</span><span class="o">]</span> <span class="o">=</span> <span class="n">response</span><span class="o">.</span><span class="n">xpath</span><span class="p">(</span><span class="s1">&#39;//title/text()&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">extract</span><span class="p">()</span><span class="o">[</span><span class="mi">0</span><span class="o">]</span>
        <span class="n">item</span><span class="o">[</span><span class="s1">&#39;movie_dir&#39;</span><span class="o">]</span> <span class="o">=</span> <span class="s1">&#39;导演:&#39;</span> <span class="o">+</span> <span class="s1">&#39;/&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">response</span><span class="o">.</span><span class="n">xpath</span><span class="p">(</span><span class="s1">&#39;//div[@id=&quot;info&quot;]/span[1]/span/a/text()&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">extract</span><span class="p">())</span>
        <span class="n">item</span><span class="o">[</span><span class="s1">&#39;movie_editors&#39;</span><span class="o">]</span> <span class="o">=</span> <span class="s1">&#39;编剧:&#39;</span> <span class="o">+</span> <span class="s1">&#39;/&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">response</span><span class="o">.</span><span class="n">xpath</span><span class="p">(</span><span class="s1">&#39;//div[@id=&quot;info&quot;]/span[2]/span/a/text()&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">extract</span><span class="p">())</span>
        <span class="n">item</span><span class="o">[</span><span class="s1">&#39;movie_actors&#39;</span><span class="o">]</span> <span class="o">=</span> <span class="s1">&#39;主演:&#39;</span> <span class="o">+</span> <span class="s1">&#39;/&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">response</span><span class="o">.</span><span class="n">xpath</span><span class="p">(</span><span class="s1">&#39;//div[@id=&quot;info&quot;]/span[3]/span/a/text()&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">extract</span><span class="p">())</span>
        <span class="n">item</span><span class="o">[</span><span class="s1">&#39;movie_type&#39;</span><span class="o">]</span> <span class="o">=</span> <span class="s1">&#39;类型:&#39;</span> <span class="o">+</span> <span class="s1">&#39;/&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">response</span><span class="o">.</span><span class="n">xpath</span><span class="p">(</span><span class="err">&#39;</span><span class="o">//</span><span class="n">div</span><span class="o">[</span><span class="vi">@id</span><span class="o">=</span><span class="s2">&quot;info&quot;</span><span class="o">]/</span><span class="n">span</span><span class="o">[</span><span class="vi">@property</span><span class="o">=</span>

        <span class="k">yield</span> <span class="n">item</span>
</pre></div>
</td></tr></table>

<p>提取到所需的信息后，用 <code>yield</code> 关键字将 item传递给 pipelines.py进行进一步的处理</p>
<h2 id="_10">三、对提取到的信息进行储存<a class="headerlink" href="#_10" title="Permanent link">&para;</a></h2>
<p>pipelines.py文件获得item后将会调用管道函数来对item进行处理，这里我们把电影的信息保存到 txt文件中去，代码如下：</p>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17
18
19
20</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="c1"># -*- coding: utf-8 -*-</span>
<span class="c1">#pipelines.py</span>

<span class="k">class</span> <span class="nc">DoubanPipeline</span><span class="p">(</span><span class="n">object</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="nb">self</span><span class="p">):</span>
        <span class="nb">self</span><span class="o">.</span><span class="n">fo</span> <span class="o">=</span> <span class="nb">open</span><span class="p">(</span><span class="s1">&#39;info.txt&#39;</span><span class="p">,</span> <span class="s1">&#39;wb&#39;</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">process_item</span><span class="p">(</span><span class="nb">self</span><span class="p">,</span> <span class="n">item</span><span class="p">,</span> <span class="n">spider</span><span class="p">):</span>
        <span class="nb">self</span><span class="o">.</span><span class="n">fo</span><span class="o">.</span><span class="n">write</span><span class="p">((</span><span class="n">item</span><span class="o">[</span><span class="s1">&#39;movie_name&#39;</span><span class="o">]</span> <span class="o">+</span> <span class="s1">&#39;\n&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="s1">&#39;utf-8&#39;</span><span class="p">))</span>
        <span class="nb">self</span><span class="o">.</span><span class="n">fo</span><span class="o">.</span><span class="n">write</span><span class="p">((</span><span class="n">item</span><span class="o">[</span><span class="s1">&#39;movie_dir&#39;</span><span class="o">]</span> <span class="o">+</span> <span class="s1">&#39;\n&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="s1">&#39;utf-8&#39;</span><span class="p">))</span>
        <span class="nb">self</span><span class="o">.</span><span class="n">fo</span><span class="o">.</span><span class="n">write</span><span class="p">((</span><span class="n">item</span><span class="o">[</span><span class="s1">&#39;movie_editor&#39;</span><span class="o">]</span> <span class="o">+</span> <span class="s1">&#39;\n&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="s1">&#39;utf-8&#39;</span><span class="p">))</span>
        <span class="nb">self</span><span class="o">.</span><span class="n">fo</span><span class="o">.</span><span class="n">write</span><span class="p">((</span><span class="n">item</span><span class="o">[</span><span class="s1">&#39;movie_actors&#39;</span><span class="o">]</span> <span class="o">+</span> <span class="s1">&#39;\n&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="s1">&#39;utf-8&#39;</span><span class="p">))</span>
        <span class="nb">self</span><span class="o">.</span><span class="n">fo</span><span class="o">.</span><span class="n">write</span><span class="p">((</span><span class="n">item</span><span class="o">[</span><span class="s1">&#39;movie_type&#39;</span><span class="o">]</span> <span class="o">+</span> <span class="s1">&#39;\n&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="s1">&#39;utf-8&#39;</span><span class="p">))</span>

        <span class="c1">#这里必须返回item，否则程序会一直等待，直到返回item为止</span>
        <span class="k">return</span> <span class="n">item</span>

    <span class="k">def</span> <span class="nf">close_spider</span><span class="p">(</span><span class="nb">self</span><span class="p">,</span> <span class="n">spider</span><span class="p">):</span>
        <span class="nb">self</span><span class="o">.</span><span class="n">fo</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
    <span class="c1">#__init__, 和close_spider 函数相当于c++里的构造函数和析构函数</span>
</pre></div>
</td></tr></table>

<h2 id="settingpy-doubanpipeline">四、在 setting.py里开启 DoubanPipeline管道<a class="headerlink" href="#settingpy-doubanpipeline" title="Permanent link">&para;</a></h2>
<p>这里只截取部分相关的代码：</p>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="x"># Obey robots.txt rules</span>
<span class="x">#是否遵循网站对爬虫的规则，一般设为False，但默认为True</span>
<span class="x">ROBOTSTXT_OBEY = False</span>

<span class="x"># Configure item pipelines</span>
<span class="x"># See https://doc.scrapy.org/en/latest/topics/item-pipeline.html</span>
<span class="x">ITEM_PIPELINES = {</span>
<span class="x">   &#39;douban.pipelines.DoubanPipeline&#39;: 300,</span>
<span class="x">}</span>

<span class="x">#设置请求头，模拟浏览器</span>
<span class="x"># Crawl responsibly by identifying yourself (and your website) on the user-agent</span>
<span class="x">USER_AGENT = &#39;Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/65.0.3325.181 Safari/537.36&#39;</span>

<span class="x"># Override the default request headers:</span>
<span class="x">DEFAULT_REQUEST_HEADERS = {</span>
<span class="x">&#39;Accept&#39;: &#39;text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8&#39;,</span>
<span class="x">&#39;Accept-Encoding&#39;: &#39;gzip, deflate, br&#39;,</span>
<span class="x">&#39;Accept-Language&#39;: &#39;zh-CN,zh;q=0.9&#39;,</span>
<span class="x">&#39;Cache-Control&#39;: &#39;max-age=0&#39;,</span>
<span class="x">&#39;Connection&#39;: &#39;keep-alive&#39;,</span>
<span class="x">&#39;Cookie&#39;: &#39;bid=uzUipzgnxdY; ll=&quot;118267&quot;; __utmc=30149280; __utmz=30149280.1523088054.4.4.utmcsr=baidu|utmccn=(organic)|utmcmd=organic; __utmc=223695111; __utmz=223695111.1523088054.1.1.utmcsr=baidu|utmccn=(organic)|utmcmd=organic; __yadk_uid=u46EFxFlzD46PvWysMULc80N9s8k2pp4; _vwo_uuid_v2=DC94F00058615E2C6A432CB494EEB894B|64bbcc3ac402b9490e5de18ce3216c5f; _pk_ref.100001.4cf6=%5B%22%22%2C%22%22%2C1523092410%2C%22https%3A%2F%2Fwww.baidu.com%2Flink%3Furl%3DFIqLEYPF6UnylF-ja19vuuKZ51u3u5gGYJHpVJ5MRTO-oLkJ_C84HBgYi5OulPwl%26wd%3D%26eqid%3Dd260482b00005bbb000000055ac87ab2%22%5D; _pk_id.100001.4cf6=cbf515d686eadc0b.1523088053.2.1523092410.1523088087.; _pk_ses.100001.4cf6=*; __utma=30149280.1054682088.1514545233.1523088054.1523092410.5; __utmb=30149280.0.10.1523092410; __utma=223695111.979367240.1523088054.1523088054.1523092410.2; __utmb=223695111.0.10.1523092410&#39;,</span>
<span class="x">&#39;Host&#39;: &#39;movie.douban.com&#39;,</span>
<span class="x">&#39;Upgrade-Insecure-Requests&#39;: &#39;1&#39;,</span>
<span class="x">}</span>
</pre></div>
</td></tr></table>

<h2 id="_11">五、运行爬虫<a class="headerlink" href="#_11" title="Permanent link">&para;</a></h2>
<p>进入到爬虫项目的文件夹里执行如下命令：</p>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1</pre></div></td><td class="code"><div class="codehilite"><pre><span></span>scrapy crawl movieInfo   
</pre></div>
</td></tr></table>

<blockquote>
<p>注意这里的名字是<img alt="image-20200714160007401" src="../024 scrapy爬虫框架.image/image-20200714160007401.png" /></p>
<p>要是用错了就会报错</p>
</blockquote>
<h2 id="scrapy-itemspy-spiders-pipelinespy-settingspy">总结：scrapy爬虫构建顺序 items.py&rarr;spiders&rarr;pipelines.py&rarr;settings.py<a class="headerlink" href="#scrapy-itemspy-spiders-pipelinespy-settingspy" title="Permanent link">&para;</a></h2>
<p>原文： <a href="https://blog.csdn.net/qq_40695895/article/details/79842502">https://blog.csdn.net/qq_40695895/article/details/79842502</a></p>
<h1 id="scrapy_5">scrapy爬虫框架（三）：爬取壁纸保存并命名<a class="headerlink" href="#scrapy_5" title="Permanent link">&para;</a></h1>
<h2 id="_12">写在开始之前<a class="headerlink" href="#_12" title="Permanent link">&para;</a></h2>
<p>按照上一篇介绍过的 scrapy爬虫的创建顺序，我们开始爬取壁纸的爬虫的创建。</p>
<p>首先，我们先过一遍 scrapy爬虫的创建顺序：</p>
<ul>
<li>第一步：确定要在pipelines里进行处理的数据，写好items文件</li>
<li>第二步：创建爬虫文件，将所需要的信息从网站上爬取下来，并传递给pipelines文件处理</li>
<li>第三步：pipelines接收spiders传递过来的数据，并做出相应的处理，如：壁纸的下载和保存</li>
<li>第四步：一定要记得在settings开启pipelines</li>
</ul>
<p>在开始之前，我们先按照上面的步骤来分析一下代码怎么写：</p>
<ol>
<li>
<p>第一步：确定我们要爬取的网站，在百度上随便找一个，
     <a href="http://desk.zol.com.cn/dongman/1920x1080/">zol</a>：<a href="http://desk.zol.com.cn/dongman/1920x1080/">http://desk.zol.com.cn/dongman/1920x1080/</a>，
     这是zol的动漫板块，自己练手的话可以另外找一个。</p>
</li>
<li>
<p>第二步：确定items，我们要下载壁纸并且按照网站上的名字进行命名。</p>
<p>下载壁纸需要获取壁纸的链接 image_url，命名需要壁纸的名字 image_name</p>
</li>
<li>
<p>第三步：编写spiders的代码从网页中获取我们image_url和image_name</p>
</li>
<li>
<p>第四步：下载图片并命名保存</p>
</li>
<li>
<p>第五步：到settings里开启pipelines</p>
</li>
</ol>
<p>下面正式开始敲代码&lt;(￣︶￣)↗[GO!]</p>
<h2 id="scrapy_6">一、创建scrapy爬虫项目<a class="headerlink" href="#scrapy_6" title="Permanent link">&para;</a></h2>
<p>打开命令行，依次输入如下命令：</p>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1
2
3
4
5
6</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="p">#</span><span class="nn">创建scrapy爬虫项目</span>
<span class="nt">scrapy</span> <span class="nt">startproject</span> <span class="nt">bizhi_zol</span>
<span class="p">#</span><span class="nn">打开新创建的爬虫项目</span>
<span class="nt">cd</span> <span class="nt">bizhi_zol</span>
<span class="p">#</span><span class="nn">在项目里创建spiders</span><span class="err">，</span><span class="nt">domain为desk</span><span class="p">.</span><span class="nc">zol</span><span class="p">.</span><span class="nc">com</span><span class="p">.</span><span class="nc">cn</span>
<span class="nt">scrapy</span> <span class="nt">genspider</span> <span class="nt">zol</span> <span class="s2">&quot;desk.zol.com.cn&quot;</span>
</pre></div>
</td></tr></table>

<h2 id="itemspy">二、items.py<a class="headerlink" href="#itemspy" title="Permanent link">&para;</a></h2>
<p>项目创建完成后，我们按照上面的顺序，先写items</p>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="c1"># -*- coding: utf-8 -*-</span>
<span class="c1">#items.py</span>

<span class="c1"># Define here the models for your scraped items</span>
<span class="c1">#</span>
<span class="c1"># See documentation in:</span>
<span class="c1"># https://doc.scrapy.org/en/latest/topics/items.html</span>

<span class="kn">import</span> <span class="nn">scrapy</span>

<span class="k">class</span> <span class="nc">BizhiZolItem</span><span class="p">(</span><span class="n">scrapy</span><span class="o">.</span><span class="n">Item</span><span class="p">):</span>
    <span class="c1"># define the fields for your item here like:</span>
    <span class="c1"># name = scrapy.Field()</span>
    <span class="n">image_url</span> <span class="o">=</span> <span class="n">scrapy</span><span class="o">.</span><span class="n">Field</span><span class="p">()</span>  <span class="c1">#图片的地址</span>
    <span class="n">image_name</span> <span class="o">=</span> <span class="n">scrapy</span><span class="o">.</span><span class="n">Field</span><span class="p">()</span> <span class="c1"># 图片的名字</span>
</pre></div>
</td></tr></table>

<h2 id="spiders">三、spiders<a class="headerlink" href="#spiders" title="Permanent link">&para;</a></h2>
<p>这一步可以说是整个爬虫里最重要的一步了</p>
<p>首先我们先分析网页结构，打开网址：<a href="http://desk.zol.com.cn/dongman/1920x1080/">http://desk.zol.com.cn/dongman/1920x1080/</a></p>
<p>查看元素后发现壁纸链接全在ul标签下</p>
<p>xpath路径如下：</p>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1
2
3</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="err">#注意！！！</span>
<span class="err">#</span><span class="n">pic</span><span class="p">-</span><span class="n">list2</span><span class="err">（两个空格）</span><span class="n">clearfix</span>
<span class="c1">//ul[@class=&quot;pic-list2  clearfix&quot;]/li/a</span>
</pre></div>
</td></tr></table>

<p>通过xpath我们得到的是壁纸下载页面的链接</p>
<p>再通过链接获取壁纸下载页面，再在下载页面内获得壁纸链接和名字</p>
<p>细节不再赘述，xpath路径如下：</p>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1
2
3
4
5
6
7
8</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="c1">#内容详情页 获取壁纸名字</span>
<span class="sr">//</span><span class="n">a</span><span class="o">[</span><span class="vi">@id</span><span class="o">=</span><span class="s2">&quot;titleName&quot;</span><span class="o">]/</span><span class="n">text</span><span class="p">()</span>
<span class="c1">#内容详情页 获取壁纸下载页面</span>
<span class="c1">#//dd[@id=&quot;tagfbl&quot;]/a[@id=&quot;1920x1200&quot;]/@href</span>
<span class="sr">//</span><span class="n">dd</span><span class="o">[</span><span class="vi">@id</span><span class="o">=</span><span class="s2">&quot;tagfbl&quot;</span><span class="o">]/</span><span class="n">a</span><span class="o">[</span><span class="mi">1</span><span class="o">]/</span><span class="vi">@href</span>

<span class="c1">#壁纸下载页 获取壁纸下载链接</span>
<span class="sr">//</span><span class="n">body</span><span class="o">/</span><span class="n">img</span><span class="o">[</span><span class="mi">1</span><span class="o">]/</span><span class="vi">@src</span>
</pre></div>
</td></tr></table>

<p>spiders代码如下：</p>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="c1"># -*- coding: utf-8 -*-</span>
<span class="c1">#zol.py</span>

<span class="n">import</span> <span class="n">scrapy</span>
<span class="n">from</span> <span class="n">bizhi_zol</span><span class="o">.</span><span class="n">items</span> <span class="n">import</span> <span class="no">BizhiZolItem</span>

<span class="k">class</span> <span class="nc">ZolSpider</span><span class="p">(</span><span class="n">scrapy</span><span class="o">.</span><span class="n">Spider</span><span class="p">):</span>
    <span class="nb">name</span> <span class="o">=</span> <span class="s1">&#39;zol&#39;</span>
    <span class="c1">#allowed_domains = [&#39;desk.zol.com.cn&#39;]</span>
    <span class="n">start_urls</span> <span class="o">=</span> <span class="o">[</span><span class="s1">&#39;http://desk.zol.com.cn/dongman/1920x1080/&#39;</span><span class="o">]</span>

    <span class="c1">#主站链接 用来拼接网址</span>
    <span class="n">base_site</span> <span class="o">=</span> <span class="s1">&#39;http://desk.zol.com.cn&#39;</span>

    <span class="k">def</span> <span class="nf">parse</span><span class="p">(</span><span class="nb">self</span><span class="p">,</span> <span class="n">response</span><span class="p">):</span>
        <span class="c1">#获取内容详情页链接</span>
        <span class="n">load_page_urls</span> <span class="o">=</span> <span class="n">response</span><span class="o">.</span><span class="n">xpath</span><span class="p">(</span><span class="s1">&#39;//ul[@class=&quot;pic-list2  clearfix&quot;]/li/a/@href&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">extract</span><span class="p">()</span>

        <span class="k">for</span> <span class="n">load_page_url</span> <span class="k">in</span> <span class="ss">load_page_urls</span><span class="p">:</span>
            <span class="n">url</span> <span class="o">=</span> <span class="nb">self</span><span class="o">.</span><span class="n">base_site</span> <span class="o">+</span> <span class="n">load_page_url</span>
            <span class="c1">#获取内容详情页页面 交给getInfo处理</span>
            <span class="nb">print</span><span class="p">(</span><span class="n">url</span><span class="p">)</span>
            <span class="k">yield</span> <span class="n">scrapy</span><span class="o">.</span><span class="n">Request</span><span class="p">(</span><span class="n">url</span><span class="p">,</span> <span class="n">callback</span><span class="o">=</span><span class="nb">self</span><span class="o">.</span><span class="n">getInfo</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">getInfo</span><span class="p">(</span><span class="nb">self</span><span class="p">,</span> <span class="n">response</span><span class="p">):</span>
        <span class="c1">#定义item储存信息</span>
        <span class="n">item</span> <span class="o">=</span> <span class="no">BizhiZolItem</span><span class="p">()</span>
        <span class="c1">#获取壁纸名字</span>
        <span class="n">item</span><span class="o">[</span><span class="s1">&#39;image_name&#39;</span><span class="o">]</span> <span class="o">=</span> <span class="n">response</span><span class="o">.</span><span class="n">xpath</span><span class="p">(</span><span class="s1">&#39;//a[@id=&quot;titleName&quot;]/text()&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">extract</span><span class="p">()</span><span class="o">[</span><span class="mi">0</span><span class="o">]</span>
        <span class="nb">print</span><span class="p">(</span><span class="n">item</span><span class="o">[</span><span class="s1">&#39;image_name&#39;</span><span class="o">]</span><span class="p">)</span>

        <span class="c1">#获取壁纸下载页面链接</span>
        <span class="c1">#load_page = self.base_site + response.xpath(&#39;//dd[@id=&quot;tagfbl&quot;]/a[@id=&quot;1920x1200&quot;]/@href&#39;).extract()[0]</span>
        <span class="c1">#测试时发现并不是所有的壁纸都有1920x1200的分辨率，所以将代码修改如下，获得壁纸最大分辨率的链接</span>
        <span class="n">load_page</span> <span class="o">=</span> <span class="nb">self</span><span class="o">.</span><span class="n">base_site</span> <span class="o">+</span> <span class="n">response</span><span class="o">.</span><span class="n">xpath</span><span class="p">(</span><span class="s1">&#39;//dd[@id=&quot;tagfbl&quot;]/a[1]/@href&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">extract</span><span class="p">()</span><span class="o">[</span><span class="mi">0</span><span class="o">]</span>

        <span class="c1">#获取壁纸下载页面 并将item作为参数传递给getLoadUrl</span>
        <span class="n">request</span> <span class="o">=</span> <span class="n">scrapy</span><span class="o">.</span><span class="n">Request</span><span class="p">(</span><span class="n">load_page</span><span class="p">,</span> <span class="n">callback</span><span class="o">=</span><span class="nb">self</span><span class="o">.</span><span class="n">getLoadUrl</span><span class="p">)</span>
        <span class="n">request</span><span class="o">.</span><span class="n">meta</span><span class="o">[</span><span class="s1">&#39;item&#39;</span><span class="o">]</span> <span class="o">=</span> <span class="n">item</span>

        <span class="k">yield</span> <span class="n">request</span>

    <span class="k">def</span> <span class="nf">getLoadUrl</span><span class="p">(</span><span class="nb">self</span><span class="p">,</span> <span class="n">response</span><span class="p">):</span>
        <span class="c1">#接收参数</span>
        <span class="n">item</span> <span class="o">=</span> <span class="n">response</span><span class="o">.</span><span class="n">meta</span><span class="o">[</span><span class="s1">&#39;item&#39;</span><span class="o">]</span>

        <span class="c1">#获取壁纸下载链接</span>
        <span class="n">item</span><span class="o">[</span><span class="s1">&#39;image_url&#39;</span><span class="o">]</span> <span class="o">=</span> <span class="n">response</span><span class="o">.</span><span class="n">xpath</span><span class="p">(</span><span class="s1">&#39;//body/img[1]/@src&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">extract</span><span class="p">()</span><span class="o">[</span><span class="mi">0</span><span class="o">]</span>

        <span class="c1">#将item传递给pipelines处理</span>
        <span class="k">yield</span> <span class="n">item</span>
</pre></div>
</td></tr></table>

<h2 id="pipelinespy">四、pipelines.py<a class="headerlink" href="#pipelinespy" title="Permanent link">&para;</a></h2>
<p>我们已经通过 spiders获得了图片的名字和链接，接下来我们只要下载图片然后再命名保存即可。</p>
<p>下载图片和之前的下载小说不同，这里要用到 ImagesPipeline中的 <code>get_media_requests</code> 方法来进行下载。</p>
<p>这里简单介绍一下get_media_requests方法：</p>
<p>选中get_media_requests然后转到定义，可以看到get_media_requests方法的原型为：</p>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1
2</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">get_media_requests</span><span class="p">(</span><span class="nb">self</span><span class="p">,</span> <span class="n">item</span><span class="p">,</span> <span class="n">info</span><span class="p">):</span>
        <span class="k">return</span> <span class="o">[</span><span class="no">Request</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="k">in</span> <span class="n">item</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="nb">self</span><span class="o">.</span><span class="n">images_urls_field</span><span class="p">,</span> <span class="o">[]</span><span class="p">)</span><span class="o">]</span>
</pre></div>
</td></tr></table>

<p>可以看到get_media_requests有三个参数，</p>
<p>第一个是self，这个不必多说；</p>
<p>第二个是 item，这个就是 spiders传递过来的 item</p>
<p>第三个是 info，看名字就知道这是用来保存信息的，至于是什么信息，info其实是一个用来保存保存图片的名字和下载链接的列表</p>
<p>但是我们想要重命名的话必须得有图片的路径，这时候就需要 item_completed方法了，原型如下：</p>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1
2
3
4</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">item_completed</span><span class="p">(</span><span class="nb">self</span><span class="p">,</span> <span class="n">results</span><span class="p">,</span> <span class="n">item</span><span class="p">,</span> <span class="n">info</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">isinstance</span><span class="p">(</span><span class="n">item</span><span class="p">,</span> <span class="n">dict</span><span class="p">)</span> <span class="ow">or</span> <span class="nb">self</span><span class="o">.</span><span class="n">images_result_field</span> <span class="k">in</span> <span class="n">item</span><span class="o">.</span><span class="n">fields</span><span class="p">:</span>
            <span class="n">item</span><span class="o">[</span><span class="nb">self</span><span class="o">.</span><span class="n">images_result_field</span><span class="o">]</span> <span class="o">=</span> <span class="o">[</span><span class="n">x</span> <span class="k">for</span> <span class="n">ok</span><span class="p">,</span> <span class="n">x</span> <span class="k">in</span> <span class="n">results</span> <span class="k">if</span> <span class="n">ok</span><span class="o">]</span>
        <span class="k">return</span> <span class="n">item</span>
</pre></div>
</td></tr></table>

<p>注意到 item_completed里有个 results参数，results参数保存了图片下载的相关信息，我们将它打印出来看看：</p>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="x">[(True, {&#39;url&#39;: &#39;https://desk-fd.zol-img.com.cn/t_s1920x1200c5/g5/M00/01/04/ChMkJ1q2H1-IDTMjAAT0D9iUubUAAm_uwJN1eoABPQn240.jpg&#39;, &#39;path&#39;: &#39;full/fedfedc2f28c22996af50ff8d4759e7031950517.jpg&#39;, &#39;checksum&#39;: &#39;06bde14f40a64c288bd251ebbe17bc1e&#39;})]</span>
</pre></div>
</td></tr></table>

<p>了解了这些后，问题就简单了。</p>
<p>我们只需要在 <code>get_media_requests</code> 中 <code>scrapy.Request()</code> 发起请求，然后 scrapy会自动将图片下载并保存。</p>
<p>当图片下载完成之后，我们再对图片重命名即可。</p>
<p>代码如下:</p>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="c1"># -*- coding: utf-8 -*-</span>
<span class="c1">#pipelines.py</span>

<span class="c1"># Define your item pipelines here</span>
<span class="c1">#</span>
<span class="c1"># Don&#39;t forget to add your pipeline to the ITEM_PIPELINES setting</span>
<span class="c1"># See: https://doc.scrapy.org/en/latest/topics/item-pipeline.html</span>

<span class="kn">from</span> <span class="nn">scrapy.pipelines.images</span> <span class="kn">import</span> <span class="n">ImagesPipeline</span>
<span class="kn">from</span> <span class="nn">bizhi_zol.settings</span> <span class="kn">import</span> <span class="n">IMAGES_STORE</span> <span class="k">as</span> <span class="n">image_store</span>
<span class="kn">import</span> <span class="nn">scrapy</span>
<span class="kn">import</span> <span class="nn">os</span>


<span class="k">class</span> <span class="nc">BizhiZolPipeline</span><span class="p">(</span><span class="n">ImagesPipeline</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">get_media_requests</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">item</span><span class="p">,</span> <span class="n">info</span><span class="p">):</span>
        <span class="c1">#发起壁纸下载请求</span>
        <span class="k">yield</span> <span class="n">scrapy</span><span class="o">.</span><span class="n">Request</span><span class="p">(</span><span class="n">item</span><span class="p">[</span><span class="s1">&#39;image_url&#39;</span><span class="p">])</span>

    <span class="k">def</span> <span class="nf">item_completed</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">results</span><span class="p">,</span> <span class="n">item</span><span class="p">,</span> <span class="n">info</span><span class="p">):</span>
        <span class="c1">#对壁纸进行重命名</span>
        <span class="n">os</span><span class="o">.</span><span class="n">rename</span><span class="p">(</span><span class="n">image_store</span> <span class="o">+</span> <span class="s1">&#39;/&#39;</span> <span class="o">+</span> <span class="n">results</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">1</span><span class="p">][</span><span class="s1">&#39;path&#39;</span><span class="p">],</span> <span class="n">image_store</span> <span class="o">+</span> <span class="s1">&#39;/&#39;</span> <span class="o">+</span> <span class="n">item</span><span class="p">[</span><span class="s1">&#39;image_name&#39;</span><span class="p">]</span> <span class="o">+</span> <span class="s1">&#39;.jpg&#39;</span><span class="p">)</span>

    <span class="k">def</span> <span class="fm">__del__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="c1">#完成后删除full目录</span>
        <span class="n">os</span><span class="o">.</span><span class="n">removedirs</span><span class="p">(</span><span class="n">image_store</span> <span class="o">+</span> <span class="s1">&#39;/&#39;</span> <span class="o">+</span> <span class="s1">&#39;full&#39;</span><span class="p">)</span>
</pre></div>
</td></tr></table>

<h2 id="settingspy">五、settings.py<a class="headerlink" href="#settingspy" title="Permanent link">&para;</a></h2>
<p>这里 settings文件需要注意的是，要添加一个 IMAGES_STORE变量来设置图片下载的目录，其他的设置不再多说，贴上代码：</p>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17
18
19
20</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="x">#settings.py</span>

<span class="x">BOT_NAME = &#39;bizhi_zol&#39;</span>

<span class="x">SPIDER_MODULES = [&#39;bizhi_zol.spiders&#39;]</span>
<span class="x">NEWSPIDER_MODULE = &#39;bizhi_zol.spiders&#39;</span>

<span class="x">IMAGES_STORE = &#39;./IMAGE&#39;</span>

<span class="x"># Crawl responsibly by identifying yourself (and your website) on the user-agent</span>
<span class="x">USER_AGENT = &#39;Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/65.0.3325.181 Safari/537.36&#39;</span>

<span class="x"># Obey robots.txt rules</span>
<span class="x">ROBOTSTXT_OBEY = False</span>

<span class="x"># Configure item pipelines</span>
<span class="x"># See https://doc.scrapy.org/en/latest/topics/item-pipeline.html</span>
<span class="x">ITEM_PIPELINES = {</span>
<span class="x">   &#39;bizhi_zol.pipelines.BizhiZolPipeline&#39;: 300,</span>
<span class="x">}</span>
</pre></div>
</td></tr></table>

<p>写到这里整个爬虫程序就完成了，不过这个爬虫程序只能爬取一页的壁纸，不能够自动翻页。</p>
<p>要实现自动翻页，就留给读者自己动脑筋了</p>
<p>ps: 自动翻页很简单，只需在原来代码的基础上增加几行代码就可以了</p>
<p><img alt="image-20200714164722030" src="../024 scrapy爬虫框架.image/image-20200714164722030.png" /></p>
<p><img alt="image-20200714164742782" src="../024 scrapy爬虫框架.image/image-20200714164742782.png" /></p>
<h2 id="_13">六进行爬取<a class="headerlink" href="#_13" title="Permanent link">&para;</a></h2>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="n">scrapy</span> <span class="n">crawl</span> <span class="n">zol</span>
</pre></div>
</td></tr></table>

<h1 id="scrapyscrapy-yield">scrapy爬虫框架（四）：scrapy中 yield使用详解<a class="headerlink" href="#scrapyscrapy-yield" title="Permanent link">&para;</a></h1>
<h2 id="_14">开始前的准备工作：<a class="headerlink" href="#_14" title="Permanent link">&para;</a></h2>
<p>MySQL下载：<a href="https://dev.mysql.com/downloads/windows/installer/5.7.html">点我</a>
python MySQL驱动下载：pymysql（pyMySql，直接用pip方式安装）</p>
<p>全部安装好之后，我们来熟悉一下pymysql模块</p>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="kn">import</span> <span class="nn">pymysql</span>

<span class="c1">#创建链接对象</span>
<span class="n">connection</span> <span class="o">=</span> <span class="n">pymysql</span><span class="o">.</span><span class="n">connect</span><span class="p">(</span><span class="n">host</span><span class="o">=</span><span class="s1">&#39;127.0.0.1&#39;</span><span class="p">,</span> <span class="n">port</span><span class="o">=</span><span class="mi">3306</span><span class="p">,</span> <span class="n">user</span><span class="o">=</span><span class="s1">&#39;root&#39;</span><span class="p">,</span> <span class="n">password</span><span class="o">=</span><span class="s1">&#39;1234&#39;</span><span class="p">,</span> <span class="n">db</span><span class="o">=</span><span class="s1">&#39;python&#39;</span><span class="p">)</span>
<span class="c1">#创建游标 游标用来进行查询，修改等操作</span>
<span class="n">cursor</span> <span class="o">=</span> <span class="n">connection</span><span class="o">.</span><span class="n">cursor</span><span class="p">()</span>

<span class="c1">#定义sql语句 这里的sql语法根据使用的数据库不同会有一些小差别</span>
<span class="n">sql</span> <span class="o">=</span> <span class="s2">&quot;SELECT * FROM python.text_info where text_title=&#39;test&#39;&quot;</span>

<span class="c1">#执行sql语句 返回受到影响的行数</span>
<span class="n">cursor</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="n">sql</span><span class="p">)</span>

<span class="c1">#获取sql语句执行后的返回数据 默认返回的数据类型为元组</span>
<span class="c1">#获取所有返回</span>
<span class="n">r</span> <span class="o">=</span> <span class="n">cursor</span><span class="o">.</span><span class="n">fetchall</span><span class="p">()</span>
<span class="c1">#获取一个返回</span>
<span class="n">r</span> <span class="o">=</span> <span class="n">cursor</span><span class="o">.</span><span class="n">fetchone</span><span class="p">()</span>
<span class="c1">#获取至多三个返回 不足三个时返回所有</span>
<span class="n">r</span> <span class="o">=</span> <span class="n">cursor</span><span class="o">.</span><span class="n">fetchmany</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>
<span class="c1">#其他的fetch方法可自行百度</span>

<span class="c1">#将返回数据类型改为字典</span>
<span class="n">cursor</span> <span class="o">=</span> <span class="n">connection</span><span class="o">.</span><span class="n">cursor</span><span class="p">(</span><span class="n">cursor</span><span class="o">=</span><span class="n">pymysql</span><span class="o">.</span><span class="n">cursors</span><span class="o">.</span><span class="n">DictCursor</span><span class="p">)</span>
<span class="c1">#或者在创建连接对象时指定返回数据类型为字典 建议把返回类型修改为字典类型</span>
<span class="n">connection</span> <span class="o">=</span> <span class="n">pymysql</span><span class="o">.</span><span class="n">connect</span><span class="p">(</span><span class="n">host</span><span class="o">=</span><span class="s1">&#39;127.0.0.1&#39;</span><span class="p">,</span> <span class="n">port</span><span class="o">=</span><span class="mi">3306</span><span class="p">,</span> <span class="n">user</span><span class="o">=</span><span class="s1">&#39;root&#39;</span><span class="p">,</span> <span class="n">password</span><span class="o">=</span><span class="s1">&#39;1234&#39;</span><span class="p">,</span> <span class="n">db</span><span class="o">=</span><span class="s1">&#39;python&#39;</span><span class="p">,</span> <span class="n">cursorclass</span><span class="o">=</span><span class="n">pymysql</span><span class="o">.</span><span class="n">cursors</span><span class="o">.</span><span class="n">DictCursor</span><span class="p">)</span>

<span class="c1">#保存所做的修改 在连接关闭之前，如果你没有调用下面的语句</span>
<span class="c1">#那么，你之前的所有修改将不会被保存</span>
<span class="n">connection</span><span class="o">.</span><span class="n">commit</span><span class="p">()</span>

<span class="c1">#关闭游标</span>
<span class="n">cursor</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
<span class="c1">#关闭连接</span>
<span class="n">connection</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
</pre></div>
</td></tr></table>

<h2 id="items">一、确定items<a class="headerlink" href="#items" title="Permanent link">&para;</a></h2>
<p>我们要爬取的网站是：<a href="http://m.50zw.la/">http://m.50zw.la</a>(网址打不开了,参考翻页的代码以及对数据库的操作即可)
要爬取的是小说的信息，如图：</p>
<p><img alt="img" src="../024 scrapy爬虫框架.image/8516750-a43030af8cee4412.png" /></p>
<p>所以items.py文件如下：</p>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="kn">import</span> <span class="nn">scrapy</span>


<span class="k">class</span> <span class="nc">TextInfoItem</span><span class="p">(</span><span class="n">scrapy</span><span class="o">.</span><span class="n">Item</span><span class="p">):</span>
    <span class="c1"># name = scrapy.Field()</span>
    <span class="n">text_name</span> <span class="o">=</span> <span class="n">scrapy</span><span class="o">.</span><span class="n">Field</span><span class="p">()</span>
    <span class="n">text_author</span> <span class="o">=</span> <span class="n">scrapy</span><span class="o">.</span><span class="n">Field</span><span class="p">()</span>
    <span class="n">text_type</span> <span class="o">=</span> <span class="n">scrapy</span><span class="o">.</span><span class="n">Field</span><span class="p">()</span>
    <span class="n">text_status</span> <span class="o">=</span> <span class="n">scrapy</span><span class="o">.</span><span class="n">Field</span><span class="p">()</span>
    <span class="n">text_latest</span> <span class="o">=</span> <span class="n">scrapy</span><span class="o">.</span><span class="n">Field</span><span class="p">()</span>
    <span class="n">text_intro</span> <span class="o">=</span> <span class="n">scrapy</span><span class="o">.</span><span class="n">Field</span><span class="p">()</span>
</pre></div>
</td></tr></table>

<p>最后信息是要储存到数据库里的，所以我们还得创建一个数据库表。</p>
<ul>
<li>第一步：在开始菜单里找到MySQL Workbench，双击打开。MySQL Workbench是MySQL自带的一个可视化管理工具</li>
<li>第二步：在 MySQL Workbench里连接数据库，并创建一个数据库 python，然后再在刚刚创建的数据库里创建一个表 text_info</li>
<li>第三步：在 text_info表里逐一添加 text_name，text_author 等属性，类型全部设置为 varchar，大小除了 text_intro是 1000外，其他的全部设置为 50</li>
</ul>
<p>MySQL的使用就不详细讲了。如果遇到问题，欢迎评论留言。</p>
<h2 id="_15">二、爬取信息<a class="headerlink" href="#_15" title="Permanent link">&para;</a></h2>
<p>为了简单，我们只爬取 50zw网站下的玄幻分类的小说信息。</p>
<p>细节前面已经讲过了，这里不再多讲，有不懂的可以去看前面的几篇文章。</p>
<p>废话不多说，直接上代码：</p>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="n">import</span> <span class="n">scrapy</span>
<span class="n">from</span> <span class="n">text_info</span><span class="o">.</span><span class="n">items</span> <span class="n">import</span> <span class="no">TextInfoItem</span>

<span class="k">class</span> <span class="nc">A50zwSpider</span><span class="p">(</span><span class="n">scrapy</span><span class="o">.</span><span class="n">Spider</span><span class="p">):</span>
    <span class="nb">name</span> <span class="o">=</span> <span class="s1">&#39;50zw&#39;</span>
    <span class="n">allowed_domains</span> <span class="o">=</span> <span class="o">[</span><span class="s1">&#39;m.50zw.la&#39;</span><span class="o">]</span>
    <span class="n">start_urls</span> <span class="o">=</span> <span class="o">[</span><span class="s1">&#39;http://m.50zw.la/wapsort/1_1.html&#39;</span><span class="o">]</span>

    <span class="c1">#主站链接 用来拼接</span>
    <span class="n">base_site</span> <span class="o">=</span> <span class="s1">&#39;http://m.50zw.la&#39;</span>

    <span class="k">def</span> <span class="nf">parse</span><span class="p">(</span><span class="nb">self</span><span class="p">,</span> <span class="n">response</span><span class="p">):</span>
        <span class="n">book_urls</span> <span class="o">=</span> <span class="n">response</span><span class="o">.</span><span class="n">xpath</span><span class="p">(</span><span class="s1">&#39;//table[@class=&quot;list-item&quot;]//a/@href&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">extract</span><span class="p">()</span>

        <span class="k">for</span> <span class="n">book_url</span> <span class="k">in</span> <span class="ss">book_urls</span><span class="p">:</span>
            <span class="n">url</span> <span class="o">=</span> <span class="nb">self</span><span class="o">.</span><span class="n">base_site</span> <span class="o">+</span> <span class="n">book_url</span>
            <span class="k">yield</span> <span class="n">scrapy</span><span class="o">.</span><span class="n">Request</span><span class="p">(</span><span class="n">url</span><span class="p">,</span> <span class="n">callback</span><span class="o">=</span><span class="nb">self</span><span class="o">.</span><span class="n">getInfo</span><span class="p">)</span>

        <span class="c1">#获取下一页</span>
        <span class="n">next_page_url</span> <span class="o">=</span> <span class="nb">self</span><span class="o">.</span><span class="n">base_site</span> <span class="o">+</span> <span class="n">response</span><span class="o">.</span><span class="n">xpath</span><span class="p">(</span><span class="s1">&#39;//table[@class=&quot;page-book&quot;]//a[contains(text(),&quot;下一页&quot;)]/@href&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">extract</span><span class="p">()</span><span class="o">[</span><span class="mi">0</span><span class="o">]</span>
        <span class="k">yield</span> <span class="n">scrapy</span><span class="o">.</span><span class="n">Request</span><span class="p">(</span><span class="n">next_page_url</span><span class="p">,</span> <span class="n">callback</span><span class="o">=</span><span class="nb">self</span><span class="o">.</span><span class="n">parse</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">getInfo</span><span class="p">(</span><span class="nb">self</span><span class="p">,</span> <span class="n">response</span><span class="p">):</span>
        <span class="n">item</span> <span class="o">=</span> <span class="no">TextInfoItem</span><span class="p">()</span>

        <span class="c1">#提取信息</span>
        <span class="n">item</span><span class="o">[</span><span class="s1">&#39;text_id&#39;</span><span class="o">]</span> <span class="o">=</span> <span class="n">response</span><span class="o">.</span><span class="n">url</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;_&#39;</span><span class="p">)</span><span class="o">[</span><span class="mi">1</span><span class="o">].</span><span class="n">replace</span><span class="p">(</span><span class="s1">&#39;/&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">)</span>
        <span class="n">item</span><span class="o">[</span><span class="s1">&#39;text_name&#39;</span><span class="o">]</span> <span class="o">=</span> <span class="n">response</span><span class="o">.</span><span class="n">xpath</span><span class="p">(</span><span class="s1">&#39;//table[1]//p/strong/text()&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">extract</span><span class="p">()</span><span class="o">[</span><span class="mi">0</span><span class="o">]</span>
        <span class="n">item</span><span class="o">[</span><span class="s1">&#39;text_author&#39;</span><span class="o">]</span> <span class="o">=</span> <span class="n">response</span><span class="o">.</span><span class="n">xpath</span><span class="p">(</span><span class="s1">&#39;//table[1]//p/a/text()&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">extract</span><span class="p">()</span><span class="o">[</span><span class="mi">0</span><span class="o">]</span>
        <span class="n">item</span><span class="o">[</span><span class="s1">&#39;text_type&#39;</span><span class="o">]</span> <span class="o">=</span> <span class="n">response</span><span class="o">.</span><span class="n">xpath</span><span class="p">(</span><span class="s1">&#39;//table[1]//p/a/text()&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">extract</span><span class="p">()</span><span class="o">[</span><span class="mi">1</span><span class="o">]</span>
        <span class="n">item</span><span class="o">[</span><span class="s1">&#39;text_status&#39;</span><span class="o">]</span> <span class="o">=</span> <span class="n">response</span><span class="o">.</span><span class="n">xpath</span><span class="p">(</span><span class="s1">&#39;//table[1]//p/text()&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">extract</span><span class="p">()</span><span class="o">[</span><span class="mi">2</span><span class="o">][</span><span class="mi">3</span><span class="p">:</span><span class="o">]</span>
        <span class="n">item</span><span class="o">[</span><span class="s1">&#39;text_latest&#39;</span><span class="o">]</span> <span class="o">=</span> <span class="n">response</span><span class="o">.</span><span class="n">xpath</span><span class="p">(</span><span class="s1">&#39;//table[1]//p[5]/text()&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">extract</span><span class="p">()</span><span class="o">[</span><span class="mi">0</span><span class="o">][</span><span class="mi">3</span><span class="p">:</span><span class="o">]</span>
        <span class="n">item</span><span class="o">[</span><span class="s1">&#39;text_intro&#39;</span><span class="o">]</span> <span class="o">=</span> <span class="n">response</span><span class="o">.</span><span class="n">xpath</span><span class="p">(</span><span class="s1">&#39;//div[@class=&quot;intro&quot;]/text()&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">extract</span><span class="p">()</span><span class="o">[</span><span class="mi">0</span><span class="o">]</span>

        <span class="k">yield</span> <span class="n">item</span>
</pre></div>
</td></tr></table>

<p>这里我们通过 <code>yield</code> 来发起一个请求，并通过 <code>callback</code> 参数为这个请求添加回调函数，在请求完成之后会将响应作为参数传递给回调函数。</p>
<p>scrapy框架会根据 <code>yield</code> 返回的实例类型来执行不同的操作，如果是 <code>scrapy.Request</code> 对象，scrapy框架会去获得该对象指向的链接并在请求完成后调用该对象的回调函数。</p>
<p>如果是 <code>scrapy.Item</code> 对象，scrapy框架会将这个对象传递给 pipelines.py做进一步处理。</p>
<p>这里我们有三个地方使用了 <code>yield</code> ，第一个地方是：</p>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1
2
3</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="x"> for book_url in book_urls:</span>
<span class="x">        url = self.base_site + book_url</span>
<span class="x">        yield scrapy.Request(url, callback=self.getInfo)</span>
</pre></div>
</td></tr></table>

<p>这里我们在循环里不断提取小说详细页面的链接，并通过 <code>yield</code> 来发起请求，并且还将函数 <code>getInfo</code> 作为回调函数来从响应中提取所需的数据。</p>
<p>第二个地方是：</p>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1
2
3</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="x">#获取下一页</span>
<span class="x">next_page_url = self.base_site + response.xpath(&#39;//table[@class=&quot;page-book&quot;]//a[contains(text(),&quot;下一页&quot;)]/@href&#39;).extract()[0]</span>
<span class="x">yield scrapy.Request(next_page_url, callback=self.parse)</span>
</pre></div>
</td></tr></table>

<p>这里是在爬取完一页的信息后，我们在当前页面获取到了下一页的链接，然后通过 <code>yield</code> 发起请求，并且将 <code>parse</code> 自己作为回调函数来处理下一页的响应。</p>
<p>这有点像递归，不过递归是函数自己调用自己，这里看起来好像是 <code>parse</code> 调用了自己，但实际上 <code>parse</code> 是由 scrapy框架在获得响应后调用的。</p>
<p>最后一处使用了 <code>yield</code> 的地方在 <code>getInfo</code> 函数里：</p>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1
2
3
4
5
6
7</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">getInfo</span><span class="p">(</span><span class="nb">self</span><span class="p">,</span> <span class="n">response</span><span class="p">):</span>
        <span class="n">item</span> <span class="o">=</span> <span class="no">TextInfoItem</span><span class="p">()</span>

        <span class="o">...</span> <span class="o">...</span>

        <span class="n">item</span><span class="o">[</span><span class="s1">&#39;text_intro&#39;</span><span class="o">]</span> <span class="o">=</span> <span class="n">response</span><span class="o">.</span><span class="n">xpath</span><span class="p">(</span><span class="s1">&#39;//div[@class=&quot;intro&quot;]/text()&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">extract</span><span class="p">()</span><span class="o">[</span><span class="mi">0</span><span class="o">]</span>
        <span class="k">yield</span> <span class="n">item</span>
</pre></div>
</td></tr></table>

<p>这里我们通过 <code>yield</code> 返回的不是 <code>Request</code> 对象，而是一个 <code>TextInfoItem</code> 对象。</p>
<p>scrap有框架获得这个对象之后，会将这个对象传递给 pipelines.py来做进一步处理。</p>
<p>我们将在 pipelines.py里将传递过来的 <code>scrapy.Item</code> 对象保存到数据库里去。</p>
<h2 id="_16">三、将信息插入数据库<a class="headerlink" href="#_16" title="Permanent link">&para;</a></h2>
<p>python对数据库的操作很简单，我们简单了解一下步骤：</p>
<ol>
<li>建立数据库连接</li>
<li>创建操作游标</li>
<li>写sql语句</li>
<li>执行sql语句</li>
<li>如果执行的是查询语句，则用fetch语句获取查询结果</li>
<li>如果执行的是插入、删除等对数据库造成了影响的sql语句，还需要执行commit保存修改</li>
</ol>
<p>贴上代码：</p>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="n">import</span> <span class="n">pymysql</span>

<span class="k">class</span> <span class="nc">TextInfoPipeline</span><span class="p">(</span><span class="n">object</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="nb">self</span><span class="p">):</span>
        <span class="c1">#建立数据库连接</span>
        <span class="nb">self</span><span class="o">.</span><span class="n">connection</span> <span class="o">=</span> <span class="n">pymysql</span><span class="o">.</span><span class="n">connect</span><span class="p">(</span><span class="n">host</span><span class="o">=</span><span class="s1">&#39;127.0.0.1&#39;</span><span class="p">,</span> <span class="n">port</span><span class="o">=</span><span class="mi">3306</span><span class="p">,</span> <span class="n">user</span><span class="o">=</span><span class="s1">&#39;root&#39;</span><span class="p">,</span> <span class="n">password</span><span class="o">=</span><span class="s1">&#39;1234&#39;</span><span class="p">,</span> <span class="n">db</span><span class="o">=</span><span class="s1">&#39;python&#39;</span><span class="p">,</span><span class="n">charset</span><span class="o">=</span><span class="s1">&#39;utf8&#39;</span><span class="p">)</span>
        <span class="c1">#创建操作游标</span>
        <span class="nb">self</span><span class="o">.</span><span class="n">cursor</span> <span class="o">=</span> <span class="nb">self</span><span class="o">.</span><span class="n">connection</span><span class="o">.</span><span class="n">cursor</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">process_item</span><span class="p">(</span><span class="nb">self</span><span class="p">,</span> <span class="n">item</span><span class="p">,</span> <span class="n">spider</span><span class="p">):</span>
        <span class="c1">#定义sql语句</span>
        <span class="n">sql</span> <span class="o">=</span> <span class="s2">&quot;INSERT INTO `python`.`text_info` (`text_id`, `text_name`, `text_author`, `text_type`, `text_status`, `text_latest`, `text_intro`) VALUES (&#39;&quot;</span><span class="o">+</span><span class="n">item</span><span class="o">[</span><span class="s1">&#39;text_id&#39;</span><span class="o">]+</span><span class="s2">&quot;&#39;, &#39;&quot;</span><span class="o">+</span><span class="n">item</span><span class="o">[</span><span class="s1">&#39;text_name&#39;</span><span class="o">]+</span><span class="s2">&quot;&#39;, &#39;&quot;</span><span class="o">+</span><span class="n">item</span><span class="o">[</span><span class="s1">&#39;text_author&#39;</span><span class="o">]+</span><span class="s2">&quot;&#39;, &#39;&quot;</span><span class="o">+</span><span class="n">item</span><span class="o">[</span><span class="s1">&#39;text_type&#39;</span><span class="o">]+</span><span class="s2">&quot;&#39;, &#39;&quot;</span><span class="o">+</span><span class="n">item</span><span class="o">[</span><span class="s1">&#39;text_status&#39;</span><span class="o">]+</span><span class="s2">&quot;&#39;, &#39;&quot;</span><span class="o">+</span><span class="n">item</span><span class="o">[</span><span class="s1">&#39;text_latest&#39;</span><span class="o">]+</span><span class="s2">&quot;&#39;, &#39;&quot;</span><span class="o">+</span><span class="n">item</span><span class="o">[</span><span class="s1">&#39;text_intro&#39;</span><span class="o">]+</span><span class="s2">&quot;&#39;);&quot;</span>

        <span class="c1">#执行sql语句</span>
        <span class="nb">self</span><span class="o">.</span><span class="n">cursor</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="n">sql</span><span class="p">)</span>
        <span class="c1">#保存修改</span>
        <span class="nb">self</span><span class="o">.</span><span class="n">connection</span><span class="o">.</span><span class="n">commit</span><span class="p">()</span>

        <span class="k">return</span> <span class="n">item</span>

    <span class="k">def</span> <span class="nf">__del__</span><span class="p">(</span><span class="nb">self</span><span class="p">):</span>
        <span class="c1">#关闭操作游标</span>
        <span class="nb">self</span><span class="o">.</span><span class="n">cursor</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
        <span class="c1">#关闭数据库连接</span>
        <span class="nb">self</span><span class="o">.</span><span class="n">connection</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
</pre></div>
</td></tr></table>

<h2 id="_17">写在最后：<a class="headerlink" href="#_17" title="Permanent link">&para;</a></h2>
<ol>
<li>代码敲好后不要忘记在settings里开启pipelines</li>
<li>pymsql连接时默认的编码是latin-1，所以在建立数据库连接时会增加参数charset来修改编码，要修改为utf-8的话得用charset=’utf8‘，而不是charset=’utf-8‘</li>
<li>这个网站有些问题，会时不时报404错误，所以在爬的过程中会报list index out of range,这是因为得到了错误的网页，xpath找不到对应得路径返回了空列表。这是正常现象，并不是代码出问题了（当然，如果频繁报错最好是检查一下代码）</li>
</ol>
<p>贴一张成功后的图片：</p>
<p><img alt="img" src="../024 scrapy爬虫框架.image/8516750-917f02f1d44f01cd.png" /></p>
<p>最后的最后，觉得我写的不错的话记得关注我哦。</p>
<h2 id="scrapy_7">scrapy的暂停与重启<a class="headerlink" href="#scrapy_7" title="Permanent link">&para;</a></h2>
<p>在爬取大型站点的时候，或遇到某些特殊情况的时候，往往需要赞同爬虫，并稍后再接着之前执行到的位置继续爬取，而不是每次出问题都从头开始。
 scrapy的暂停与重启的设置很简单：
 1.创建工作目录</p>
<ul>
<li>在当前项目下，创建工作目录(文件夹)，命名如：crawls</li>
<li>不同的spider是不能用同一个目录的。
     该工作目录是用来保存运行中的爬虫的必须数据，以保持作业状态的。</li>
</ul>
<p>2.用以下命令启动爬虫</p>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1</pre></div></td><td class="code"><div class="codehilite"><pre><span></span>scrapy crawl somespider -s JOBDIR=crawls/somespider-1
</pre></div>
</td></tr></table>

<p>上述命令中：
 <code>somespider</code>: 启动的爬虫名
 <code>crawls/somespider-1</code>:你创建的工作目录+爬虫序号</p>
<p>后面的somespider-1是用来区分不同的爬虫的，因为官方文档提到了：</p>
<blockquote>
<p>要启用持久性支持，您只需通过JOBDIR设置定义作业目录。该目录将用于存储所有必需的数据以保持单个作业的状态（即蜘蛛运行）。重要的是要注意，此目录不能由不同的蜘蛛共享，甚至不能由同一个蜘蛛的不同作业/运行共享，因为它意味着用于存储单个作业的状态</p>
</blockquote>
<p>3.暂停爬虫</p>
<p>以上两步，爬虫便可以能暂停的状态运行，当你需要暂停的时候，只需在运行窗口发送暂停命令即可：
 <strong>ctrl + c</strong>
 <em>tips：</em></p>
<ul>
<li>只能按一次该命令，按两次的话爬虫会被强制退出。</li>
<li>爬虫程序不会立刻暂停，它需要处理完已经发送出的请求完成善后工作，需要耐心等待一会儿。</li>
</ul>
<p>4.暂停后的重启</p>
<p>输入与启动相同的命令即可：</p>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1</pre></div></td><td class="code"><div class="codehilite"><pre><span></span>scrapy crawl somespider -s JOBDIR=crawls/somespider-1
</pre></div>
</td></tr></table>

<p>然后爬虫就会接着上一次暂停后的位置继续运行。</p>
                
                  
                
              
              
                


              
            </article>
          </div>
        </div>
      </main>
      
        
<footer class="md-footer">
  
    <div class="md-footer-nav">
      <nav class="md-footer-nav__inner md-grid">
        
          <a href="../025 PostMan使用教程/" title="025 PostMan使用教程" class="md-flex md-footer-nav__link md-footer-nav__link--prev" rel="prev">
            <div class="md-flex__cell md-flex__cell--shrink">
              <i class="md-icon md-icon--arrow-back md-footer-nav__button"></i>
            </div>
            <div class="md-flex__cell md-flex__cell--stretch md-footer-nav__title">
              <span class="md-flex__ellipsis">
                <span class="md-footer-nav__direction">
                  上一页
                </span>
                025 PostMan使用教程
              </span>
            </div>
          </a>
        
        
          <a href="../023 正则表达式/" title="023 正则表达式" class="md-flex md-footer-nav__link md-footer-nav__link--next" rel="next">
            <div class="md-flex__cell md-flex__cell--stretch md-footer-nav__title">
              <span class="md-flex__ellipsis">
                <span class="md-footer-nav__direction">
                  下一页
                </span>
                023 正则表达式
              </span>
            </div>
            <div class="md-flex__cell md-flex__cell--shrink">
              <i class="md-icon md-icon--arrow-forward md-footer-nav__button"></i>
            </div>
          </a>
        
      </nav>
    </div>
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-footer-copyright">
        
        <!-- powered by
        <a href="https://www.mkdocs.org">MkDocs</a>
        and
        <a href="https://squidfunk.github.io/mkdocs-material/">
          Material for MkDocs</a> -->
      </div>
      
    </div>
  </div>
</footer>
      
    </div>
    
      <script src="../../assets/javascripts/application.ac79c3b0.js"></script>
      
        
        
          
          <script src="../../assets/javascripts/lunr/lunr.stemmer.support.js"></script>
          
            
              
                <script src="../../assets/javascripts/lunr/tinyseg.js"></script>
              
              
                <script src="../../assets/javascripts/lunr/lunr.ja.js"></script>
              
            
          
          
        
      
      <script>app.initialize({version:"1.0.4",url:{base:"../.."}})</script>
      
        <script src="../../js/extra.js"></script>
      
        <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-MML-AM_CHTML"></script>
      
    
  </body>
</html>